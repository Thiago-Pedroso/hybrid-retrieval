{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graph NER Validation Lab\n",
        "\n",
        "ValidaÃ§Ã£o isolada do NER para o retriever de grafo (entidades), com foco em:\n",
        "- Verificar carregamento correto dos backends (sem fallback regex)\n",
        "- Construir IDF e avaliar desempenho do slice de grafo\n",
        "- Comparar backends/parametrizaÃ§Ãµes por dataset\n",
        "\n",
        "Modelo de embedding de entidade fixo: `sentence-transformers/all-MiniLM-L6-v2`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ macOS env set\n",
            "Repo root: /Users/thiago/Documents/GitHub/hybrid-retrieval\n"
          ]
        }
      ],
      "source": [
        "import sys, os, platform, warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# macOS safety\n",
        "if platform.system() == 'Darwin':\n",
        "    os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
        "    os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "    print(\"âœ“ macOS env set\")\n",
        "\n",
        "import multiprocessing\n",
        "try:\n",
        "    multiprocessing.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    pass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Optional\n",
        "from collections import Counter\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "%matplotlib inline\n",
        "\n",
        "# repo root\n",
        "repo_root = Path.cwd()\n",
        "while repo_root != repo_root.parent and repo_root.name != 'hybrid-retrieval':\n",
        "    repo_root = repo_root.parent\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "print(f\"Repo root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Imports concluÃ­dos\n"
          ]
        }
      ],
      "source": [
        "# project imports\n",
        "from src.datasets.loader import load_beir_dataset, select_split, as_documents, as_queries\n",
        "from src.datasets.schema import Document, Query\n",
        "from src.retrievers.graph_faiss import GraphRetriever\n",
        "from src.encoders.entity_encoder import EntityEncoderReal, NERConfig, CacheConfig\n",
        "from src.encoders.encoders import HFSemanticEncoder\n",
        "from src.eval.evaluator import evaluate_predictions\n",
        "\n",
        "print(\"âœ“ Imports concluÃ­dos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify_ner_backend(encoder: EntityEncoderReal, expected_backend: str) -> bool:\n",
        "    try:\n",
        "        import spacy\n",
        "    except Exception:\n",
        "        print(\"âŒ spaCy nÃ£o instalado\")\n",
        "        return False\n",
        "    if encoder._nlp is None:\n",
        "        print(f\"âŒ Fallback regex detectado (backend {expected_backend})\")\n",
        "        return False\n",
        "    ok = isinstance(encoder._nlp, spacy.Language)\n",
        "    pipes = getattr(encoder._nlp, 'pipe_names', [])\n",
        "    model = encoder._nlp.meta.get('name', 'unknown') if hasattr(encoder._nlp, 'meta') else 'unknown'\n",
        "    print(f\"âœ“ NER carregado: {expected_backend} | modelo: {model} | pipes: {pipes}\")\n",
        "    if 'ner' not in pipes:\n",
        "        print(\"âš ï¸ Pipe 'ner' nÃ£o ativo (a extraÃ§Ã£o pode depender de noun_chunks)\")\n",
        "    return ok\n",
        "\n",
        "def load_subset_dataset(dataset_name: str, n_docs: int = 150, n_queries: int = 30):\n",
        "    root = repo_root / 'data' / dataset_name / 'processed' / 'beir'\n",
        "    corpus, queries, qrels = load_beir_dataset(root)\n",
        "    split = select_split(qrels, (\"test\",\"dev\",\"validation\",\"train\"))\n",
        "    split_eval = \"test\" if \"test\" in set(qrels[\"split\"]) else split\n",
        "    qrels_eval = qrels[qrels[\"split\"] == split_eval].copy()\n",
        "    qids_with_rel = set(qrels_eval[\"query_id\"].unique())\n",
        "    queries_eval = queries[queries[\"query_id\"].isin(qids_with_rel)].copy()\n",
        "    if len(queries_eval) > n_queries:\n",
        "        queries_eval = queries_eval.head(n_queries)\n",
        "        qids = set(queries_eval[\"query_id\"].unique())\n",
        "        qrels_eval = qrels_eval[qrels_eval[\"query_id\"].isin(qids)]\n",
        "    rel_doc_ids = set(qrels_eval[\"doc_id\"].unique())\n",
        "    docs_rel = corpus[corpus[\"doc_id\"].isin(rel_doc_ids)].copy()\n",
        "    if len(docs_rel) < n_docs:\n",
        "        docs_other = corpus[~corpus[\"doc_id\"].isin(rel_doc_ids)].sample(\n",
        "            n=min(n_docs - len(docs_rel), len(corpus) - len(docs_rel)), random_state=42\n",
        "        )\n",
        "        docs_subset = pd.concat([docs_rel, docs_other]).reset_index(drop=True)\n",
        "    else:\n",
        "        docs_subset = docs_rel.head(n_docs)\n",
        "    docs = as_documents(docs_subset)\n",
        "    qlist = as_queries(queries_eval)\n",
        "    print(f\"ðŸ“Š {dataset_name.upper()}: {len(docs)} docs, {len(qlist)} queries, {len(qrels_eval)} qrels\")\n",
        "    return docs, qlist, qrels_eval, [(d.title or '') + ' ' + (d.text or '') for d in docs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Carregando Datasets ===\n",
            "\n",
            "ðŸ“Š SCIFACT: 25 docs, 5 queries, 6 qrels\n",
            "âœ“ scifact carregado\n",
            "\n",
            "ðŸ“Š FIQA: 25 docs, 5 queries, 11 qrels\n",
            "âœ“ fiqa carregado\n",
            "\n",
            "ðŸ“Š NFCORPUS: 25 docs, 5 queries, 234 qrels\n",
            "âœ“ nfcorpus carregado\n",
            "\n",
            "âœ… Total: 3 datasets carregados\n"
          ]
        }
      ],
      "source": [
        "# Carregar datasets (subsets)\n",
        "print(\"=== Carregando Datasets ===\\n\")\n",
        "\n",
        "datasets = {}\n",
        "for name in [\"scifact\", \"fiqa\", \"nfcorpus\"]:\n",
        "    try:\n",
        "        docs, queries, qrels, doc_texts = load_subset_dataset(name, n_docs=25, n_queries=5)\n",
        "        datasets[name] = dict(docs=docs, queries=queries, qrels=qrels, doc_texts=doc_texts)\n",
        "        print(f\"âœ“ {name} carregado\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao carregar {name}: {e}\\n\")\n",
        "\n",
        "print(f\"âœ… Total: {len(datasets)} datasets carregados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Baseline NER por domÃ­nio (min_df=1, noun_chunks=False, max_entities=256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- SCIFACT ---\n",
            "  Backend=scispacy | model=en_ner_bionlp13cg_md\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
            "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: scispacy | modelo: ner_bionlp13cg_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "2025-11-03 09:41:44 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:41:44 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:41:44 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:41:45 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m722.8ms\u001b[0m\n",
            "2025-11-03 09:41:45 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=269\n",
            "2025-11-03 09:41:45 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m723.7ms\u001b[0m\n",
            "2025-11-03 09:41:45 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:41:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m2.08s\u001b[0m\n",
            "2025-11-03 09:41:47 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:41:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.7ms\u001b[0m\n",
            "2025-11-03 09:41:47 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "  nDCG@10=0.5326 | MRR@10=0.3933\n",
            "  Backend=scispacy | model=en_core_sci_md\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "2025-11-03 09:42:02 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:42:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:42:02 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:42:03 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m688.3ms\u001b[0m\n",
            "2025-11-03 09:42:03 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:42:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m689.1ms\u001b[0m\n",
            "2025-11-03 09:42:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:42:08 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.38s\u001b[0m\n",
            "2025-11-03 09:42:08 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:42:08 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:42:08 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "  nDCG@10=0.7209 | MRR@10=0.6450\n",
            "\n",
            "--- FIQA ---\n",
            "  Backend=spacy | model=en_core_web_md\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "2025-11-03 09:42:13 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:42:13 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:42:13 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:42:14 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m578.3ms\u001b[0m\n",
            "2025-11-03 09:42:14 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:42:14 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m579.3ms\u001b[0m\n",
            "2025-11-03 09:42:14 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:42:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m999.6ms\u001b[0m\n",
            "2025-11-03 09:42:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:42:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:42:15 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "  nDCG@10=0.6541 | MRR@10=0.6600\n",
            "\n",
            "--- NFCORPUS ---\n",
            "  Backend=scispacy | model=en_core_sci_md\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "2025-11-03 09:42:28 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:42:28 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:42:28 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:42:29 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m748.6ms\u001b[0m\n",
            "2025-11-03 09:42:29 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 09:42:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m749.4ms\u001b[0m\n",
            "2025-11-03 09:42:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:42:33 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m4.62s\u001b[0m\n",
            "2025-11-03 09:42:33 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:42:33 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:42:33 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "  nDCG@10=0.1728 | MRR@10=0.4000\n",
            "\n",
            "=== Baselines NER ===\n",
            "                               scifact    fiqa  nfcorpus\n",
            "scispacy:en_ner_bionlp13cg_md   0.5326     NaN       NaN\n",
            "scispacy:en_core_sci_md         0.7209     NaN    0.1728\n",
            "spacy:en_core_web_md               NaN  0.6541       NaN\n"
          ]
        }
      ],
      "source": [
        "GRAPH_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "BASE_PARAMS = dict(min_df=1, ner_use_noun_chunks=False)\n",
        "\n",
        "# ConfiguraÃ§Ãµes por dataset\n",
        "NER_BACKENDS = {\n",
        "    \"scifact\": [\n",
        "        (\"scispacy\", \"en_ner_bionlp13cg_md\"),\n",
        "        (\"scispacy\", \"en_core_sci_md\"),\n",
        "    ],\n",
        "    \"fiqa\": [\n",
        "        (\"spacy\", \"en_core_web_md\"),\n",
        "    ],\n",
        "    \"nfcorpus\": [\n",
        "        (\"scispacy\", \"en_core_sci_md\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "baseline_scores = {}\n",
        "\n",
        "for ds_name, data in datasets.items():\n",
        "    print(f\"\\n--- {ds_name.upper()} ---\")\n",
        "    scores_this = {}\n",
        "    for backend, model in NER_BACKENDS.get(ds_name, []):\n",
        "        print(f\"  Backend={backend} | model={model}\")\n",
        "        ner_cfg = NERConfig(\n",
        "            backend=backend,\n",
        "            model=model,\n",
        "            use_noun_chunks=BASE_PARAMS[\"ner_use_noun_chunks\"],\n",
        "            batch_size=16,\n",
        "            n_process=1,\n",
        "            allowed_labels=None,\n",
        "        )\n",
        "        encoder = EntityEncoderReal(\n",
        "            graph_model_name=GRAPH_MODEL,\n",
        "            device=\"cpu\",\n",
        "            ner=ner_cfg,\n",
        "            min_df=BASE_PARAMS[\"min_df\"],\n",
        "            max_entities_per_text=256,\n",
        "            cache=CacheConfig(artifact_dir=None, force_rebuild=False),\n",
        "        )\n",
        "        if not verify_ner_backend(encoder, backend):\n",
        "            print(\"  âš ï¸ Fallback detectado â€” pulando\")\n",
        "            continue\n",
        "        print(\"  Fit NER+IDF...\")\n",
        "        encoder.fit(data[\"doc_texts\"])  # fit corpus\n",
        "\n",
        "        # Avaliar retriever\n",
        "        retriever = GraphRetriever(\n",
        "            graph_model_name=GRAPH_MODEL,\n",
        "            device=\"cpu\",\n",
        "            ner_backend=backend,\n",
        "            ner_model=model,\n",
        "            ner_use_noun_chunks=BASE_PARAMS[\"ner_use_noun_chunks\"],\n",
        "            ner_batch_size=16,\n",
        "            ner_n_process=1,\n",
        "            min_df=BASE_PARAMS[\"min_df\"],\n",
        "            entity_artifact_dir=None,\n",
        "            entity_force_rebuild=True,\n",
        "        )\n",
        "        retriever.build_index(data[\"docs\"])  # encode docs\n",
        "        results = retriever.retrieve(data[\"queries\"], k=10)\n",
        "        metrics = evaluate_predictions(results, data[\"qrels\"], ks=(10,))\n",
        "        nDCG = metrics[metrics[\"k\"]==10][\"nDCG\"].iloc[0]\n",
        "        MRR = metrics[metrics[\"k\"]==10][\"MRR\"].iloc[0]\n",
        "        scores_this[f\"{backend}:{model}\"] = dict(nDCG=nDCG, MRR=MRR)\n",
        "        print(f\"  nDCG@10={nDCG:.4f} | MRR@10={MRR:.4f}\")\n",
        "    baseline_scores[ds_name] = scores_this\n",
        "\n",
        "print(\"\\n=== Baselines NER ===\")\n",
        "print(pd.DataFrame({k: {m: s[\"nDCG\"] for m,s in v.items()} for k,v in baseline_scores.items()}).round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Varredura de parÃ¢metros NER (min_df, noun_chunks, max_entities)\n",
        "\n",
        "Executa grid pequeno por dataset usando o backend NER vencedor do baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SWEEP: SCIFACT ===\n",
            "  min_df=1, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:51:18 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:51:18 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:51:18 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:51:19 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m715.4ms\u001b[0m\n",
            "2025-11-03 09:51:19 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:51:19 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m716.2ms\u001b[0m\n",
            "2025-11-03 09:51:19 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:51:24 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.22s\u001b[0m\n",
            "2025-11-03 09:51:24 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:51:24 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.5ms\u001b[0m\n",
            "2025-11-03 09:51:24 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.7209\n",
            "  min_df=1, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:51:39 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:51:39 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:51:39 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:51:40 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m696.2ms\u001b[0m\n",
            "2025-11-03 09:51:40 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:51:40 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m697.0ms\u001b[0m\n",
            "2025-11-03 09:51:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:51:45 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.31s\u001b[0m\n",
            "2025-11-03 09:51:45 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:51:45 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:51:45 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.7209\n",
            "  min_df=1, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:51:59 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:51:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:51:59 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:52:00 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m703.3ms\u001b[0m\n",
            "2025-11-03 09:52:00 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:52:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m704.1ms\u001b[0m\n",
            "2025-11-03 09:52:00 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:52:05 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.08s\u001b[0m\n",
            "2025-11-03 09:52:05 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:52:05 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:52:05 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.7209\n",
            "  min_df=1, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:52:19 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:52:19 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:52:19 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:52:19 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m975.2ms\u001b[0m\n",
            "2025-11-03 09:52:19 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:52:19 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m976.0ms\u001b[0m\n",
            "2025-11-03 09:52:19 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:52:25 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.80s\u001b[0m\n",
            "2025-11-03 09:52:25 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:52:25 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.5ms\u001b[0m\n",
            "2025-11-03 09:52:25 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.7209\n",
            "  min_df=1, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:52:39 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:52:39 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:52:39 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:52:40 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m1.02s\u001b[0m\n",
            "2025-11-03 09:52:40 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:52:40 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m1.02s\u001b[0m\n",
            "2025-11-03 09:52:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:52:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.85s\u001b[0m\n",
            "2025-11-03 09:52:46 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:52:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.5ms\u001b[0m\n",
            "2025-11-03 09:52:46 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.7209\n",
            "  min_df=1, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:53:02 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:53:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:53:02 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:53:03 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m964.3ms\u001b[0m\n",
            "2025-11-03 09:53:03 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1072\n",
            "2025-11-03 09:53:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m965.1ms\u001b[0m\n",
            "2025-11-03 09:53:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:53:09 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.25s\u001b[0m\n",
            "2025-11-03 09:53:09 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:53:09 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:53:09 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.7209\n",
            "  min_df=2, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:53:23 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:53:23 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:53:23 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:53:24 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m685.5ms\u001b[0m\n",
            "2025-11-03 09:53:24 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:53:24 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m686.2ms\u001b[0m\n",
            "2025-11-03 09:53:24 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:53:25 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.14s\u001b[0m\n",
            "2025-11-03 09:53:25 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:53:25 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:53:25 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6019\n",
            "  min_df=2, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:53:38 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:53:38 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:53:38 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:53:38 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m698.4ms\u001b[0m\n",
            "2025-11-03 09:53:38 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:53:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m699.2ms\u001b[0m\n",
            "2025-11-03 09:53:38 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:53:39 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.17s\u001b[0m\n",
            "2025-11-03 09:53:39 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:53:39 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:53:39 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6019\n",
            "  min_df=2, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:53:53 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:53:53 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:53:53 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:53:54 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m720.1ms\u001b[0m\n",
            "2025-11-03 09:53:54 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:53:54 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m721.0ms\u001b[0m\n",
            "2025-11-03 09:53:54 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:53:55 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.22s\u001b[0m\n",
            "2025-11-03 09:53:55 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:53:55 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:53:55 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6019\n",
            "  min_df=2, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:54:08 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:54:08 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:54:08 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:54:09 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m964.3ms\u001b[0m\n",
            "2025-11-03 09:54:09 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:54:09 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m965.7ms\u001b[0m\n",
            "2025-11-03 09:54:09 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:54:11 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.45s\u001b[0m\n",
            "2025-11-03 09:54:11 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:54:11 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:54:11 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6019\n",
            "  min_df=2, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:54:26 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:54:26 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:54:26 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:54:27 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m960.9ms\u001b[0m\n",
            "2025-11-03 09:54:27 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:54:27 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m961.7ms\u001b[0m\n",
            "2025-11-03 09:54:27 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:54:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.63s\u001b[0m\n",
            "2025-11-03 09:54:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:54:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:54:29 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6019\n",
            "  min_df=2, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:54:42 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:54:42 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:54:42 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:54:43 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m1.05s\u001b[0m\n",
            "2025-11-03 09:54:43 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:54:43 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m1.05s\u001b[0m\n",
            "2025-11-03 09:54:43 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:54:44 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.56s\u001b[0m\n",
            "2025-11-03 09:54:44 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:54:44 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:54:44 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6019\n",
            "  min_df=3, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:54:57 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:54:57 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:54:57 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:54:58 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m734.2ms\u001b[0m\n",
            "2025-11-03 09:54:58 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=36\n",
            "2025-11-03 09:54:58 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m735.2ms\u001b[0m\n",
            "2025-11-03 09:54:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:54:59 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m882.8ms\u001b[0m\n",
            "2025-11-03 09:54:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:54:59 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:54:59 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4394\n",
            "  min_df=3, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:55:12 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:55:12 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:55:12 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:55:13 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m691.7ms\u001b[0m\n",
            "2025-11-03 09:55:13 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=36\n",
            "2025-11-03 09:55:13 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m692.5ms\u001b[0m\n",
            "2025-11-03 09:55:13 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:55:14 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m820.9ms\u001b[0m\n",
            "2025-11-03 09:55:14 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:55:14 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:55:14 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4394\n",
            "  min_df=3, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:55:30 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:55:30 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:55:30 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:55:30 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m684.1ms\u001b[0m\n",
            "2025-11-03 09:55:30 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=36\n",
            "2025-11-03 09:55:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m684.9ms\u001b[0m\n",
            "2025-11-03 09:55:30 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:55:31 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m832.5ms\u001b[0m\n",
            "2025-11-03 09:55:31 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:55:31 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:55:31 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4394\n",
            "  min_df=3, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:55:44 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:55:44 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:55:44 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:55:45 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m940.9ms\u001b[0m\n",
            "2025-11-03 09:55:45 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=36\n",
            "2025-11-03 09:55:45 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m941.7ms\u001b[0m\n",
            "2025-11-03 09:55:45 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:55:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.18s\u001b[0m\n",
            "2025-11-03 09:55:46 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:55:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:55:46 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4394\n",
            "  min_df=3, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:55:59 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:55:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:55:59 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:56:00 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m944.2ms\u001b[0m\n",
            "2025-11-03 09:56:00 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=36\n",
            "2025-11-03 09:56:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m945.0ms\u001b[0m\n",
            "2025-11-03 09:56:00 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:56:01 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.19s\u001b[0m\n",
            "2025-11-03 09:56:01 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:56:01 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:56:01 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4394\n",
            "  min_df=3, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:56:14 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:56:14 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:56:14 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:56:15 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m953.4ms\u001b[0m\n",
            "2025-11-03 09:56:15 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=36\n",
            "2025-11-03 09:56:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m954.2ms\u001b[0m\n",
            "2025-11-03 09:56:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:56:16 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.17s\u001b[0m\n",
            "2025-11-03 09:56:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:56:16 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:56:16 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4394\n",
            "  min_df=5, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:56:29 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:56:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:56:29 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:56:29 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m690.8ms\u001b[0m\n",
            "2025-11-03 09:56:29 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=8\n",
            "2025-11-03 09:56:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m691.6ms\u001b[0m\n",
            "2025-11-03 09:56:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:56:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m724.5ms\u001b[0m\n",
            "2025-11-03 09:56:30 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:56:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:56:30 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.3487\n",
            "  min_df=5, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:56:47 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:56:47 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:56:47 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:56:48 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m712.9ms\u001b[0m\n",
            "2025-11-03 09:56:48 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=8\n",
            "2025-11-03 09:56:48 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m713.6ms\u001b[0m\n",
            "2025-11-03 09:56:48 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:56:48 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m757.4ms\u001b[0m\n",
            "2025-11-03 09:56:48 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:56:48 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:56:48 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.3487\n",
            "  min_df=5, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:57:02 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:57:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:57:02 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:57:02 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m715.3ms\u001b[0m\n",
            "2025-11-03 09:57:02 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=8\n",
            "2025-11-03 09:57:02 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m716.1ms\u001b[0m\n",
            "2025-11-03 09:57:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:57:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m768.9ms\u001b[0m\n",
            "2025-11-03 09:57:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:57:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.5ms\u001b[0m\n",
            "2025-11-03 09:57:03 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.3487\n",
            "  min_df=5, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:57:16 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:57:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:57:16 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:57:17 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m996.8ms\u001b[0m\n",
            "2025-11-03 09:57:17 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=8\n",
            "2025-11-03 09:57:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m997.7ms\u001b[0m\n",
            "2025-11-03 09:57:17 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:57:18 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.11s\u001b[0m\n",
            "2025-11-03 09:57:18 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:57:18 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:57:18 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.3487\n",
            "  min_df=5, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:57:32 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:57:32 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:57:32 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:57:33 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m979.5ms\u001b[0m\n",
            "2025-11-03 09:57:33 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=8\n",
            "2025-11-03 09:57:33 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m980.3ms\u001b[0m\n",
            "2025-11-03 09:57:33 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:57:35 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.09s\u001b[0m\n",
            "2025-11-03 09:57:35 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:57:35 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:57:35 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.3487\n",
            "  min_df=5, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 09:57:48 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:57:48 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:57:48 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:57:49 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m976.5ms\u001b[0m\n",
            "2025-11-03 09:57:49 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=8\n",
            "2025-11-03 09:57:49 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m977.9ms\u001b[0m\n",
            "2025-11-03 09:57:49 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:57:50 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.13s\u001b[0m\n",
            "2025-11-03 09:57:50 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:57:50 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:57:50 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.3487\n",
            "\n",
            "=== SWEEP: FIQA ===\n",
            "  min_df=1, noun_chunks=False, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:57:58 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:57:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:57:58 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:57:59 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m469.8ms\u001b[0m\n",
            "2025-11-03 09:57:59 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:57:59 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m470.5ms\u001b[0m\n",
            "2025-11-03 09:57:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.03s\u001b[0m\n",
            "2025-11-03 09:58:00 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:58:00 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  min_df=1, noun_chunks=False, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:05 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:05 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:05 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:05 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m469.8ms\u001b[0m\n",
            "2025-11-03 09:58:05 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:58:05 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m470.6ms\u001b[0m\n",
            "2025-11-03 09:58:05 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:06 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m892.1ms\u001b[0m\n",
            "2025-11-03 09:58:06 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:06 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:58:06 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  min_df=1, noun_chunks=False, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:14 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:14 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:14 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:15 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m470.0ms\u001b[0m\n",
            "2025-11-03 09:58:15 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:58:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m470.8ms\u001b[0m\n",
            "2025-11-03 09:58:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m899.9ms\u001b[0m\n",
            "2025-11-03 09:58:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:58:15 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  min_df=1, noun_chunks=True, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:21 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:21 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:21 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:21 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m547.2ms\u001b[0m\n",
            "2025-11-03 09:58:21 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:58:21 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m547.9ms\u001b[0m\n",
            "2025-11-03 09:58:21 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.10s\u001b[0m\n",
            "2025-11-03 09:58:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.4ms\u001b[0m\n",
            "2025-11-03 09:58:22 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  min_df=1, noun_chunks=True, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:28 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:28 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:28 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:28 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m532.0ms\u001b[0m\n",
            "2025-11-03 09:58:28 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:58:28 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m532.7ms\u001b[0m\n",
            "2025-11-03 09:58:28 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.02s\u001b[0m\n",
            "2025-11-03 09:58:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.4ms\u001b[0m\n",
            "2025-11-03 09:58:29 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  min_df=1, noun_chunks=True, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:36 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:36 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:36 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:36 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m534.4ms\u001b[0m\n",
            "2025-11-03 09:58:36 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 09:58:36 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m535.2ms\u001b[0m\n",
            "2025-11-03 09:58:36 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:37 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m988.1ms\u001b[0m\n",
            "2025-11-03 09:58:37 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:37 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:58:37 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  min_df=2, noun_chunks=False, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:42 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:42 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:42 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:43 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m488.5ms\u001b[0m\n",
            "2025-11-03 09:58:43 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5\n",
            "2025-11-03 09:58:43 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m489.3ms\u001b[0m\n",
            "2025-11-03 09:58:43 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:43 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m530.5ms\u001b[0m\n",
            "2025-11-03 09:58:43 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:43 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:58:43 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=2, noun_chunks=False, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:49 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:49 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:49 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:49 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m471.4ms\u001b[0m\n",
            "2025-11-03 09:58:49 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5\n",
            "2025-11-03 09:58:49 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m472.2ms\u001b[0m\n",
            "2025-11-03 09:58:49 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:50 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m526.4ms\u001b[0m\n",
            "2025-11-03 09:58:50 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:50 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:58:50 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=2, noun_chunks=False, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:58:55 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:58:55 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:58:55 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:58:56 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m470.4ms\u001b[0m\n",
            "2025-11-03 09:58:56 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5\n",
            "2025-11-03 09:58:56 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m471.3ms\u001b[0m\n",
            "2025-11-03 09:58:56 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:58:56 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m541.8ms\u001b[0m\n",
            "2025-11-03 09:58:56 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:58:56 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:58:56 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=2, noun_chunks=True, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:02 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:02 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:02 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m883.8ms\u001b[0m\n",
            "2025-11-03 09:59:02 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5\n",
            "2025-11-03 09:59:02 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m884.6ms\u001b[0m\n",
            "2025-11-03 09:59:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m659.2ms\u001b[0m\n",
            "2025-11-03 09:59:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:59:03 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=2, noun_chunks=True, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:13 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:13 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:13 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:14 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m555.8ms\u001b[0m\n",
            "2025-11-03 09:59:14 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5\n",
            "2025-11-03 09:59:14 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m556.5ms\u001b[0m\n",
            "2025-11-03 09:59:14 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m625.4ms\u001b[0m\n",
            "2025-11-03 09:59:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:59:15 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=2, noun_chunks=True, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:21 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:21 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:21 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:22 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m531.4ms\u001b[0m\n",
            "2025-11-03 09:59:22 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5\n",
            "2025-11-03 09:59:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m532.1ms\u001b[0m\n",
            "2025-11-03 09:59:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:23 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m619.5ms\u001b[0m\n",
            "2025-11-03 09:59:23 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:23 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:59:23 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=3, noun_chunks=False, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:28 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:28 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:28 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:29 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m482.2ms\u001b[0m\n",
            "2025-11-03 09:59:29 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 09:59:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m483.0ms\u001b[0m\n",
            "2025-11-03 09:59:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m524.8ms\u001b[0m\n",
            "2025-11-03 09:59:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:59:29 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=3, noun_chunks=False, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:40 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:40 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:40 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m475.5ms\u001b[0m\n",
            "2025-11-03 09:59:40 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 09:59:40 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m476.3ms\u001b[0m\n",
            "2025-11-03 09:59:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m498.3ms\u001b[0m\n",
            "2025-11-03 09:59:41 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 09:59:41 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=3, noun_chunks=False, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:46 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:46 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:46 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:46 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m485.0ms\u001b[0m\n",
            "2025-11-03 09:59:46 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 09:59:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m485.8ms\u001b[0m\n",
            "2025-11-03 09:59:46 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m500.8ms\u001b[0m\n",
            "2025-11-03 09:59:47 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:59:47 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=3, noun_chunks=True, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:52 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:52 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:52 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 09:59:53 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m538.1ms\u001b[0m\n",
            "2025-11-03 09:59:53 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 09:59:53 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m538.9ms\u001b[0m\n",
            "2025-11-03 09:59:53 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 09:59:54 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m613.8ms\u001b[0m\n",
            "2025-11-03 09:59:54 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 09:59:54 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 09:59:54 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=3, noun_chunks=True, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 09:59:59 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 09:59:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 09:59:59 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:00 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m558.0ms\u001b[0m\n",
            "2025-11-03 10:00:00 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m558.8ms\u001b[0m\n",
            "2025-11-03 10:00:00 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m630.0ms\u001b[0m\n",
            "2025-11-03 10:00:00 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:00:00 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=3, noun_chunks=True, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:06 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:06 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:06 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:07 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m564.2ms\u001b[0m\n",
            "2025-11-03 10:00:07 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:07 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m565.0ms\u001b[0m\n",
            "2025-11-03 10:00:07 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:07 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m613.8ms\u001b[0m\n",
            "2025-11-03 10:00:07 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:07 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:00:07 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=5, noun_chunks=False, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:16 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:16 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:16 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m479.7ms\u001b[0m\n",
            "2025-11-03 10:00:16 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:16 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m480.4ms\u001b[0m\n",
            "2025-11-03 10:00:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m502.3ms\u001b[0m\n",
            "2025-11-03 10:00:17 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:00:17 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=5, noun_chunks=False, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:22 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:22 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:23 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m469.0ms\u001b[0m\n",
            "2025-11-03 10:00:23 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:23 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m469.8ms\u001b[0m\n",
            "2025-11-03 10:00:23 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:23 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m498.2ms\u001b[0m\n",
            "2025-11-03 10:00:23 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:23 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:00:23 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=5, noun_chunks=False, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:29 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:29 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:29 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m465.5ms\u001b[0m\n",
            "2025-11-03 10:00:29 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m466.3ms\u001b[0m\n",
            "2025-11-03 10:00:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m497.3ms\u001b[0m\n",
            "2025-11-03 10:00:30 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:00:30 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=5, noun_chunks=True, max_entities=128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:40 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:40 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:40 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m529.2ms\u001b[0m\n",
            "2025-11-03 10:00:40 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:40 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m530.0ms\u001b[0m\n",
            "2025-11-03 10:00:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m598.9ms\u001b[0m\n",
            "2025-11-03 10:00:41 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:00:41 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=5, noun_chunks=True, max_entities=256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:46 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:46 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:46 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:47 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m530.8ms\u001b[0m\n",
            "2025-11-03 10:00:47 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m531.5ms\u001b[0m\n",
            "2025-11-03 10:00:47 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m606.0ms\u001b[0m\n",
            "2025-11-03 10:00:47 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:47 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.8ms\u001b[0m\n",
            "2025-11-03 10:00:47 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "  min_df=5, noun_chunks=True, max_entities=512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'parser', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:00:58 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:00:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:00:58 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:00:59 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m529.6ms\u001b[0m\n",
            "2025-11-03 10:00:59 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1\n",
            "2025-11-03 10:00:59 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m530.4ms\u001b[0m\n",
            "2025-11-03 10:00:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:00:59 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m597.6ms\u001b[0m\n",
            "2025-11-03 10:00:59 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:00:59 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:00:59 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.4556\n",
            "\n",
            "=== SWEEP: NFCORPUS ===\n",
            "  min_df=1, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:01:16 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:01:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:01:16 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:01:17 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m634.8ms\u001b[0m\n",
            "2025-11-03 10:01:17 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 10:01:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m635.5ms\u001b[0m\n",
            "2025-11-03 10:01:17 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:01:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m4.99s\u001b[0m\n",
            "2025-11-03 10:01:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:01:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:01:22 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1728\n",
            "  min_df=1, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:01:35 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:01:35 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:01:35 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:01:35 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m654.6ms\u001b[0m\n",
            "2025-11-03 10:01:35 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 10:01:35 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m655.4ms\u001b[0m\n",
            "2025-11-03 10:01:35 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:01:39 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m4.26s\u001b[0m\n",
            "2025-11-03 10:01:39 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:01:39 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.7ms\u001b[0m\n",
            "2025-11-03 10:01:39 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1728\n",
            "  min_df=1, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:01:58 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:01:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:01:58 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:01:58 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m640.4ms\u001b[0m\n",
            "2025-11-03 10:01:58 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 10:01:58 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m641.1ms\u001b[0m\n",
            "2025-11-03 10:01:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:02:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m4.37s\u001b[0m\n",
            "2025-11-03 10:02:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:02:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:02:03 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1728\n",
            "  min_df=1, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:02:16 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:02:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:02:16 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:02:17 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m892.0ms\u001b[0m\n",
            "2025-11-03 10:02:17 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 10:02:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m892.7ms\u001b[0m\n",
            "2025-11-03 10:02:17 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:02:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m5.07s\u001b[0m\n",
            "2025-11-03 10:02:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:02:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:02:22 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1728\n",
            "  min_df=1, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:02:35 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:02:35 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:02:35 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:02:36 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m937.9ms\u001b[0m\n",
            "2025-11-03 10:02:36 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 10:02:36 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m939.0ms\u001b[0m\n",
            "2025-11-03 10:02:36 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:02:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m4.66s\u001b[0m\n",
            "2025-11-03 10:02:41 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:02:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.4ms\u001b[0m\n",
            "2025-11-03 10:02:41 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1728\n",
            "  min_df=1, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:02:57 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:02:57 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:02:57 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:02:58 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m901.8ms\u001b[0m\n",
            "2025-11-03 10:02:58 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=916\n",
            "2025-11-03 10:02:58 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m902.6ms\u001b[0m\n",
            "2025-11-03 10:02:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:03:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m4.82s\u001b[0m\n",
            "2025-11-03 10:03:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:03:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:03:03 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1728\n",
            "  min_df=2, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:03:15 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:03:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:03:15 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:03:16 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m657.7ms\u001b[0m\n",
            "2025-11-03 10:03:16 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=142\n",
            "2025-11-03 10:03:16 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m658.5ms\u001b[0m\n",
            "2025-11-03 10:03:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:03:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.32s\u001b[0m\n",
            "2025-11-03 10:03:17 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:03:17 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.6ms\u001b[0m\n",
            "2025-11-03 10:03:17 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1740\n",
            "  min_df=2, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:04:01 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:04:01 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:04:01 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:04:02 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m669.8ms\u001b[0m\n",
            "2025-11-03 10:04:02 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=142\n",
            "2025-11-03 10:04:02 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m670.6ms\u001b[0m\n",
            "2025-11-03 10:04:02 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:04:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.36s\u001b[0m\n",
            "2025-11-03 10:04:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:04:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:04:03 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1740\n",
            "  min_df=2, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:04:16 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:04:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:04:16 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:04:16 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m660.7ms\u001b[0m\n",
            "2025-11-03 10:04:16 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=142\n",
            "2025-11-03 10:04:16 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m661.4ms\u001b[0m\n",
            "2025-11-03 10:04:16 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:04:18 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.30s\u001b[0m\n",
            "2025-11-03 10:04:18 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:04:18 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:04:18 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1740\n",
            "  min_df=2, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:04:36 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:04:36 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:04:36 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:04:37 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m931.0ms\u001b[0m\n",
            "2025-11-03 10:04:37 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=142\n",
            "2025-11-03 10:04:37 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m931.9ms\u001b[0m\n",
            "2025-11-03 10:04:37 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:04:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.64s\u001b[0m\n",
            "2025-11-03 10:04:38 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:04:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.6ms\u001b[0m\n",
            "2025-11-03 10:04:38 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1740\n",
            "  min_df=2, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:04:54 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:04:54 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:04:54 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:04:55 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m899.9ms\u001b[0m\n",
            "2025-11-03 10:04:55 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=142\n",
            "2025-11-03 10:04:55 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m900.7ms\u001b[0m\n",
            "2025-11-03 10:04:55 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:04:57 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.59s\u001b[0m\n",
            "2025-11-03 10:04:57 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:04:57 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:04:57 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1740\n",
            "  min_df=2, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:05:10 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:05:10 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:05:10 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:05:11 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m884.7ms\u001b[0m\n",
            "2025-11-03 10:05:11 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=142\n",
            "2025-11-03 10:05:11 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m885.5ms\u001b[0m\n",
            "2025-11-03 10:05:11 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:05:12 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.59s\u001b[0m\n",
            "2025-11-03 10:05:12 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:05:12 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:05:12 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1740\n",
            "  min_df=3, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:05:25 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:05:25 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:05:25 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:05:26 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m683.0ms\u001b[0m\n",
            "2025-11-03 10:05:26 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=66\n",
            "2025-11-03 10:05:26 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m683.8ms\u001b[0m\n",
            "2025-11-03 10:05:26 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:05:27 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m944.8ms\u001b[0m\n",
            "2025-11-03 10:05:27 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:05:27 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:05:27 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1326\n",
            "  min_df=3, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:05:40 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:05:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:05:40 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:05:40 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m655.9ms\u001b[0m\n",
            "2025-11-03 10:05:40 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=66\n",
            "2025-11-03 10:05:40 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m656.6ms\u001b[0m\n",
            "2025-11-03 10:05:40 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:05:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m953.4ms\u001b[0m\n",
            "2025-11-03 10:05:41 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:05:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:05:41 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1326\n",
            "  min_df=3, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:05:58 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:05:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:05:58 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:05:58 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m682.0ms\u001b[0m\n",
            "2025-11-03 10:05:58 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=66\n",
            "2025-11-03 10:05:58 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m682.8ms\u001b[0m\n",
            "2025-11-03 10:05:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:06:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.03s\u001b[0m\n",
            "2025-11-03 10:06:00 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:06:00 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:06:00 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1326\n",
            "  min_df=3, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:06:13 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:06:13 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:06:13 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:06:14 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m898.9ms\u001b[0m\n",
            "2025-11-03 10:06:14 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=66\n",
            "2025-11-03 10:06:14 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m899.7ms\u001b[0m\n",
            "2025-11-03 10:06:14 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:06:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.32s\u001b[0m\n",
            "2025-11-03 10:06:15 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:06:15 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:06:15 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1326\n",
            "  min_df=3, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:06:28 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:06:28 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:06:28 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:06:29 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m874.5ms\u001b[0m\n",
            "2025-11-03 10:06:29 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=66\n",
            "2025-11-03 10:06:29 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m875.3ms\u001b[0m\n",
            "2025-11-03 10:06:29 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:06:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.23s\u001b[0m\n",
            "2025-11-03 10:06:30 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:06:30 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:06:30 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1326\n",
            "  min_df=3, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:06:44 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:06:44 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:06:44 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:06:45 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m877.0ms\u001b[0m\n",
            "2025-11-03 10:06:45 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=66\n",
            "2025-11-03 10:06:45 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m877.8ms\u001b[0m\n",
            "2025-11-03 10:06:45 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:06:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.23s\u001b[0m\n",
            "2025-11-03 10:06:46 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:06:46 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:06:46 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1326\n",
            "  min_df=5, noun_chunks=False, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:07:03 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:07:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:07:03 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:07:03 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m683.9ms\u001b[0m\n",
            "2025-11-03 10:07:03 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=18\n",
            "2025-11-03 10:07:03 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m684.8ms\u001b[0m\n",
            "2025-11-03 10:07:03 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:07:04 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m811.7ms\u001b[0m\n",
            "2025-11-03 10:07:04 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:07:04 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:07:04 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1215\n",
            "  min_df=5, noun_chunks=False, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:07:21 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:07:21 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:07:21 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:07:21 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m664.1ms\u001b[0m\n",
            "2025-11-03 10:07:21 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=18\n",
            "2025-11-03 10:07:21 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m664.8ms\u001b[0m\n",
            "2025-11-03 10:07:21 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:07:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m726.1ms\u001b[0m\n",
            "2025-11-03 10:07:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:07:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:07:22 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1215\n",
            "  min_df=5, noun_chunks=False, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:07:34 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:07:34 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:07:34 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:07:35 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m651.0ms\u001b[0m\n",
            "2025-11-03 10:07:35 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=18\n",
            "2025-11-03 10:07:35 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m651.8ms\u001b[0m\n",
            "2025-11-03 10:07:35 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:07:36 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m749.5ms\u001b[0m\n",
            "2025-11-03 10:07:36 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:07:36 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:07:36 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1215\n",
            "  min_df=5, noun_chunks=True, max_entities=128\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:07:49 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:07:49 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:07:49 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:07:50 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m874.4ms\u001b[0m\n",
            "2025-11-03 10:07:50 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=18\n",
            "2025-11-03 10:07:50 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m875.1ms\u001b[0m\n",
            "2025-11-03 10:07:50 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:07:51 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.04s\u001b[0m\n",
            "2025-11-03 10:07:51 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:07:51 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:07:51 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1215\n",
            "  min_df=5, noun_chunks=True, max_entities=256\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:08:04 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:08:04 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:08:04 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:08:05 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m883.9ms\u001b[0m\n",
            "2025-11-03 10:08:05 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=18\n",
            "2025-11-03 10:08:05 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m884.9ms\u001b[0m\n",
            "2025-11-03 10:08:05 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:08:06 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.04s\u001b[0m\n",
            "2025-11-03 10:08:06 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:08:06 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:08:06 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1215\n",
            "  min_df=5, noun_chunks=True, max_entities=512\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'parser', 'ner']\n",
            "2025-11-03 10:08:22 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:08:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:08:22 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:08:23 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m874.3ms\u001b[0m\n",
            "2025-11-03 10:08:23 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=18\n",
            "2025-11-03 10:08:23 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m875.0ms\u001b[0m\n",
            "2025-11-03 10:08:23 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:08:24 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.04s\u001b[0m\n",
            "2025-11-03 10:08:24 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:08:24 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:08:24 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.1215\n",
            "\n",
            "=== Melhores parÃ¢metros por dataset ===\n",
            "  scifact: nDCG=0.7209 com min_df=1, noun_chunks=False, max_entities=128\n",
            "  fiqa: nDCG=0.6541 com min_df=1, noun_chunks=False, max_entities=128\n",
            "  nfcorpus: nDCG=0.1740 com min_df=2, noun_chunks=False, max_entities=128\n"
          ]
        }
      ],
      "source": [
        "# Seleciona backend vencedor do baseline (hardcoded pelas observaÃ§Ãµes)\n",
        "BEST_NER = {\n",
        "    \"scifact\": (\"scispacy\", \"en_core_sci_md\"),\n",
        "    \"fiqa\": (\"spacy\", \"en_core_web_md\"),\n",
        "    \"nfcorpus\": (\"scispacy\", \"en_core_sci_md\"),\n",
        "}\n",
        "\n",
        "min_df_grid = [1, 2, 3, 5]\n",
        "noun_chunks_grid = [False, True]\n",
        "max_entities_grid = [128, 256, 512]\n",
        "\n",
        "sweep_results = {}\n",
        "\n",
        "for ds_name, data in datasets.items():\n",
        "    print(f\"\\n=== SWEEP: {ds_name.upper()} ===\")\n",
        "    backend, model = BEST_NER[ds_name]\n",
        "    ds_scores = []\n",
        "    for min_df in min_df_grid:\n",
        "        for use_nc in noun_chunks_grid:\n",
        "            for max_ent in max_entities_grid:\n",
        "                print(f\"  min_df={min_df}, noun_chunks={use_nc}, max_entities={max_ent}\")\n",
        "                ner_cfg = NERConfig(\n",
        "                    backend=backend,\n",
        "                    model=model,\n",
        "                    use_noun_chunks=use_nc,\n",
        "                    batch_size=16,\n",
        "                    n_process=1,\n",
        "                    allowed_labels=None,\n",
        "                )\n",
        "                encoder = EntityEncoderReal(\n",
        "                    graph_model_name=GRAPH_MODEL,\n",
        "                    device=\"cpu\",\n",
        "                    ner=ner_cfg,\n",
        "                    min_df=min_df,\n",
        "                    max_entities_per_text=max_ent,\n",
        "                    cache=CacheConfig(artifact_dir=None, force_rebuild=False),\n",
        "                )\n",
        "                if not verify_ner_backend(encoder, backend):\n",
        "                    print(\"    âš ï¸ fallback â€” pulando\")\n",
        "                    continue\n",
        "                try:\n",
        "                    encoder.fit(data[\"doc_texts\"])  # fit\n",
        "                    retriever = GraphRetriever(\n",
        "                        graph_model_name=GRAPH_MODEL,\n",
        "                        device=\"cpu\",\n",
        "                        ner_backend=backend,\n",
        "                        ner_model=model,\n",
        "                        ner_use_noun_chunks=use_nc,\n",
        "                        ner_batch_size=16,\n",
        "                        ner_n_process=1,\n",
        "                        min_df=min_df,\n",
        "                        entity_artifact_dir=None,\n",
        "                        entity_force_rebuild=True,\n",
        "                    )\n",
        "                    retriever.build_index(data[\"docs\"])  # index\n",
        "                    results = retriever.retrieve(data[\"queries\"], k=10)\n",
        "                    metrics = evaluate_predictions(results, data[\"qrels\"], ks=(10,))\n",
        "                    nDCG = metrics[metrics[\"k\"]==10][\"nDCG\"].iloc[0]\n",
        "                    ds_scores.append(dict(min_df=min_df, noun_chunks=use_nc, max_entities=max_ent, nDCG=nDCG))\n",
        "                    print(f\"    nDCG@10={nDCG:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"    ERRO: {e}\")\n",
        "    sweep_results[ds_name] = pd.DataFrame(ds_scores)\n",
        "\n",
        "# Exibir melhores por dataset\n",
        "print(\"\\n=== Melhores parÃ¢metros por dataset ===\")\n",
        "for ds_name, df in sweep_results.items():\n",
        "    if len(df) == 0:\n",
        "        print(f\"  {ds_name}: sem resultados vÃ¡lidos\")\n",
        "        continue\n",
        "    best = df.sort_values(\"nDCG\", ascending=False).iloc[0]\n",
        "    print(f\"  {ds_name}: nDCG={best['nDCG']:.4f} com min_df={int(best['min_df'])}, noun_chunks={bool(best['noun_chunks'])}, max_entities={int(best['max_entities'])}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) FIQA: labels financeiras e EntityRuler leve\n",
        "\n",
        "Testa allowed_labels e padrÃµes leves (ETF, IPO, CDS, CPI, GDP; tickers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  labels=none, entity_ruler=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:08:34 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:08:34 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:08:34 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:08:34 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m493.7ms\u001b[0m\n",
            "2025-11-03 10:08:34 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 10:08:34 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m494.5ms\u001b[0m\n",
            "2025-11-03 10:08:34 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:08:35 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.07s\u001b[0m\n",
            "2025-11-03 10:08:35 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:08:35 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:08:35 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  labels=none, entity_ruler=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'entity_ruler', 'ner']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-03 10:08:41 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:08:41 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:08:41 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:08:41 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m486.6ms\u001b[0m\n",
            "2025-11-03 10:08:41 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 10:08:41 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m487.4ms\u001b[0m\n",
            "2025-11-03 10:08:41 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:08:42 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.00s\u001b[0m\n",
            "2025-11-03 10:08:42 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:08:42 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:08:42 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  labels=finance_core, entity_ruler=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "2025-11-03 10:08:48 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:08:48 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:08:48 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:08:48 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m504.7ms\u001b[0m\n",
            "2025-11-03 10:08:48 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 10:08:48 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m505.5ms\u001b[0m\n",
            "2025-11-03 10:08:48 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:08:49 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1.04s\u001b[0m\n",
            "2025-11-03 10:08:49 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:08:49 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 10:08:49 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "  labels=finance_core, entity_ruler=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'entity_ruler', 'ner']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-03 10:08:54 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (25 documentos)\n",
            "2025-11-03 10:08:54 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 10:08:54 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 10:08:55 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m491.8ms\u001b[0m\n",
            "2025-11-03 10:08:55 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=109\n",
            "2025-11-03 10:08:55 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m492.6ms\u001b[0m\n",
            "2025-11-03 10:08:55 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 10:08:56 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m950.2ms\u001b[0m\n",
            "2025-11-03 10:08:56 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 10:08:56 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.2ms\u001b[0m\n",
            "2025-11-03 10:08:56 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 25 vetores, dim=384\n",
            "    nDCG@10=0.6541\n",
            "\n",
            "FIQA â€” melhores configs:\n",
            "         labels  ruler    nDCG\n",
            "0          none  False  0.6541\n",
            "1          none   True  0.6541\n",
            "2  finance_core  False  0.6541\n",
            "3  finance_core   True  0.6541\n"
          ]
        }
      ],
      "source": [
        "# Executar apenas em FIQA\n",
        "fiqa = datasets.get(\"fiqa\")\n",
        "fiqa_scores = []\n",
        "\n",
        "if fiqa:\n",
        "    backend, model = (\"spacy\", \"en_core_web_md\")\n",
        "    label_sets = {\n",
        "        \"none\": None,\n",
        "        \"finance_core\": [\"ORG\",\"GPE\",\"MONEY\",\"PERCENT\",\"NORP\",\"PRODUCT\"],\n",
        "    }\n",
        "    ruler_patterns = [\n",
        "        {\"label\":\"FIN_TERM\",\"pattern\":\"ETF\"},\n",
        "        {\"label\":\"FIN_TERM\",\"pattern\":\"IPO\"},\n",
        "        {\"label\":\"FIN_TERM\",\"pattern\":\"CDS\"},\n",
        "        {\"label\":\"FIN_TERM\",\"pattern\":\"CPI\"},\n",
        "        {\"label\":\"FIN_TERM\",\"pattern\":\"GDP\"},\n",
        "        {\"label\":\"TICKER\",\"pattern\":[{\"TEXT\":{\"REGEX\":\"^[A-Z]{1,5}$\"}}]},\n",
        "    ]\n",
        "    for labels_name, labels in label_sets.items():\n",
        "        for use_ruler in [False, True]:\n",
        "            print(f\"  labels={labels_name}, entity_ruler={use_ruler}\")\n",
        "            ner_cfg = NERConfig(\n",
        "                backend=backend,\n",
        "                model=model,\n",
        "                use_noun_chunks=False,\n",
        "                batch_size=16,\n",
        "                n_process=1,\n",
        "                allowed_labels=labels,\n",
        "                use_entity_ruler=use_ruler,\n",
        "                ruler_patterns=ruler_patterns if use_ruler else None,\n",
        "            )\n",
        "            encoder = EntityEncoderReal(\n",
        "                graph_model_name=GRAPH_MODEL,\n",
        "                device=\"cpu\",\n",
        "                ner=ner_cfg,\n",
        "                min_df=1,\n",
        "                max_entities_per_text=256,\n",
        "                cache=CacheConfig(artifact_dir=None, force_rebuild=True),\n",
        "            )\n",
        "            if not verify_ner_backend(encoder, backend):\n",
        "                print(\"    âš ï¸ fallback â€” pulando\")\n",
        "                continue\n",
        "            encoder.fit(fiqa[\"doc_texts\"])  # fit corpus FIQA\n",
        "            retriever = GraphRetriever(\n",
        "                graph_model_name=GRAPH_MODEL,\n",
        "                device=\"cpu\",\n",
        "                ner_backend=backend,\n",
        "                ner_model=model,\n",
        "                ner_use_noun_chunks=False,\n",
        "                ner_batch_size=16,\n",
        "                ner_n_process=1,\n",
        "                min_df=1,\n",
        "                entity_artifact_dir=None,\n",
        "                entity_force_rebuild=True,\n",
        "            )\n",
        "            retriever.build_index(fiqa[\"docs\"])  # index\n",
        "            results = retriever.retrieve(fiqa[\"queries\"], k=10)\n",
        "            metrics = evaluate_predictions(results, fiqa[\"qrels\"], ks=(10,))\n",
        "            nDCG = metrics[metrics[\"k\"]==10][\"nDCG\"].iloc[0]\n",
        "            fiqa_scores.append(dict(labels=labels_name, ruler=use_ruler, nDCG=nDCG))\n",
        "            print(f\"    nDCG@10={nDCG:.4f}\")\n",
        "\n",
        "    df_fiqa = pd.DataFrame(fiqa_scores)\n",
        "    print(\"\\nFIQA â€” melhores configs:\")\n",
        "    if len(df_fiqa):\n",
        "        print(df_fiqa.sort_values(\"nDCG\", ascending=False).head(5).round(4))\n",
        "    else:\n",
        "        print(\"(sem resultados)\")\n",
        "else:\n",
        "    print(\"FIQA nÃ£o carregado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) SciFact e NFCorpus â€” confirmaÃ§Ã£o rÃ¡pida do backend\n",
        "\n",
        "Reporta o melhor backend e os ganhos (a partir dos baselines e/ou sweep)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ConsolidaÃ§Ã£o (melhores) ===\n",
            "\n",
            "Baselines:\n",
            "                                scifact    fiqa  nfcorpus\n",
            "scispacy:en_ner_bionlp13cg_md   0.5326     NaN       NaN\n",
            "scispacy:en_core_sci_md         0.7209     NaN    0.1728\n",
            "spacy:en_core_web_md               NaN  0.6541       NaN\n",
            "\n",
            "SCIFACT â€” melhor do sweep: nDCG=0.7209 | min_df=1, noun_chunks=False, max_entities=128\n",
            "\n",
            "FIQA â€” melhor do sweep: nDCG=0.6541 | min_df=1, noun_chunks=False, max_entities=128\n",
            "\n",
            "NFCORPUS â€” melhor do sweep: nDCG=0.1740 | min_df=2, noun_chunks=False, max_entities=128\n"
          ]
        }
      ],
      "source": [
        "# ConsolidaÃ§Ã£o simples\n",
        "print(\"=== ConsolidaÃ§Ã£o (melhores) ===\")\n",
        "\n",
        "# Baselines jÃ¡ rodados\n",
        "try:\n",
        "    base_table = pd.DataFrame({k: {m: s[\"nDCG\"] for m,s in v.items()} for k,v in baseline_scores.items()}).round(4)\n",
        "    print(\"\\nBaselines:\\n\", base_table)\n",
        "except NameError:\n",
        "    print(\"(baselines nÃ£o estÃ£o em memÃ³ria)\")\n",
        "\n",
        "# Sweep\n",
        "for ds_name, df in sweep_results.items():\n",
        "    if len(df) == 0:\n",
        "        continue\n",
        "    best = df.sort_values(\"nDCG\", ascending=False).iloc[0]\n",
        "    print(f\"\\n{ds_name.upper()} â€” melhor do sweep: nDCG={best['nDCG']:.4f} | min_df={int(best['min_df'])}, noun_chunks={bool(best['noun_chunks'])}, max_entities={int(best['max_entities'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) ValidaÃ§Ã£o para um subset maior dos datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SCIFACT | subset: 500 docs, 100 queries ===\n",
            "ðŸ“Š SCIFACT: 500 docs, 100 queries, 116 qrels\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "  Build index...\n",
            "2025-11-03 19:09:38 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (500 documentos)\n",
            "2025-11-03 19:09:38 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 19:09:38 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 19:09:51 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m12.95s\u001b[0m\n",
            "2025-11-03 19:09:51 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=14047\n",
            "2025-11-03 19:09:51 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m12.95s\u001b[0m\n",
            "2025-11-03 19:09:51 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 19:10:58 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m1m 6.9s\u001b[0m\n",
            "2025-11-03 19:10:58 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 19:10:58 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.6ms\u001b[0m\n",
            "2025-11-03 19:10:58 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 500 vetores, dim=384\n",
            "  Retrieve top-50...\n",
            "  Avaliando mÃ©tricas...\n",
            "\n",
            "MÃ©tricas por @k:\n",
            " k   nDCG    MRR  Recall  Precision\n",
            " 5 0.6217 0.6007  0.7052      0.160\n",
            "10 0.6424 0.6079  0.7685      0.088\n",
            "20 0.6654 0.6135  0.8560      0.049\n",
            "\n",
            "Recall@50: 0.9000\n",
            "\n",
            "=== FIQA | subset: 500 docs, 100 queries ===\n",
            "ðŸ“Š FIQA: 500 docs, 100 queries, 267 qrels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "  Build index...\n",
            "2025-11-03 19:11:13 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (500 documentos)\n",
            "2025-11-03 19:11:13 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 19:11:13 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 19:11:22 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m9.59s\u001b[0m\n",
            "2025-11-03 19:11:22 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=1487\n",
            "2025-11-03 19:11:22 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m9.59s\u001b[0m\n",
            "2025-11-03 19:11:22 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 19:11:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m15.58s\u001b[0m\n",
            "2025-11-03 19:11:38 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 19:11:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.3ms\u001b[0m\n",
            "2025-11-03 19:11:38 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 500 vetores, dim=384\n",
            "  Retrieve top-50...\n",
            "  Avaliando mÃ©tricas...\n",
            "\n",
            "MÃ©tricas por @k:\n",
            " k   nDCG    MRR  Recall  Precision\n",
            " 5 0.1165 0.1462  0.1202      0.054\n",
            "10 0.1311 0.1563  0.1620      0.037\n",
            "20 0.1493 0.1632  0.2213      0.025\n",
            "\n",
            "Recall@50: 0.3574\n",
            "\n",
            "=== NFCORPUS | subset: 1000 docs, 150 queries ===\n",
            "ðŸ“Š NFCORPUS: 1000 docs, 150 queries, 6337 qrels\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF...\n",
            "  Build index...\n",
            "2025-11-03 19:12:20 | INFO     | retriever.graph | [graph_faiss.py:91] | ðŸš€ Building Graph Index (1000 documentos)\n",
            "2025-11-03 19:12:20 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Fit GraphVectorizer no corpus - iniciando...\n",
            "2025-11-03 19:12:20 | INFO     | graph.vectorizer | [logging.py:199] | â±ï¸  Fit Graph (NER + IDF) - iniciando...\n",
            "2025-11-03 19:12:49 | INFO     | graph.vectorizer | [logging.py:220] | âœ“ Fit Graph (NER + IDF) - concluÃ­do em \u001b[32m29.07s\u001b[0m\n",
            "2025-11-03 19:12:49 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | âœ“ Graph fitted: dim=384, ents=5281\n",
            "2025-11-03 19:12:49 | INFO     | retriever.graph | [logging.py:220] | âœ“ Fit GraphVectorizer no corpus - concluÃ­do em \u001b[32m29.07s\u001b[0m\n",
            "2025-11-03 19:12:49 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Encoding documents (Graph) - iniciando...\n",
            "2025-11-03 19:13:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Encoding documents (Graph) - concluÃ­do em \u001b[32m49.23s\u001b[0m\n",
            "2025-11-03 19:13:38 | INFO     | retriever.graph | [logging.py:199] | â±ï¸  Construindo FAISS IndexFlatIP - iniciando...\n",
            "2025-11-03 19:13:38 | INFO     | retriever.graph | [logging.py:220] | âœ“ Construindo FAISS IndexFlatIP - concluÃ­do em \u001b[32m0.5ms\u001b[0m\n",
            "2025-11-03 19:13:38 | INFO     | retriever.graph | [graph_faiss.py:111] |   âœ“ FAISS IndexFlatIP: 1000 vetores, dim=384\n",
            "  Retrieve top-50...\n",
            "  Avaliando mÃ©tricas...\n",
            "\n",
            "MÃ©tricas por @k:\n",
            " k   nDCG    MRR  Recall  Precision\n",
            " 5 0.1079 0.1582  0.0197     0.0973\n",
            "10 0.0929 0.1614  0.0244     0.0747\n",
            "20 0.0810 0.1626  0.0339     0.0567\n",
            "\n",
            "Recall@50: 0.0523\n",
            "\n",
            "=== Resumo nDCG@10 e Recall@50 (subset maior) ===\n",
            "    dataset    nDCG10  Recall50\n",
            "0   scifact  0.642394  0.900000\n",
            "1      fiqa  0.131054  0.357397\n",
            "2  nfcorpus  0.092911  0.052295\n"
          ]
        }
      ],
      "source": [
        "# === ValidaÃ§Ã£o com subsets maiores e mÃ©tricas @5/@10/@20 + Recall@50 ===\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Configs vencedoras por dataset\n",
        "BEST = {\n",
        "    \"scifact\": dict(backend=\"scispacy\", model=\"en_core_sci_md\",  min_df=1, noun_chunks=False, max_entities=128),\n",
        "    \"fiqa\":    dict(backend=\"spacy\",    model=\"en_core_web_md\",  min_df=1, noun_chunks=False, max_entities=128),\n",
        "    \"nfcorpus\":dict(backend=\"scispacy\", model=\"en_core_sci_md\",  min_df=2, noun_chunks=False, max_entities=128),\n",
        "}\n",
        "\n",
        "# Tamanhos maiores (edite se quiser)\n",
        "BIGGER = {\n",
        "    \"scifact\": dict(n_docs=500, n_queries=100),\n",
        "    \"fiqa\":    dict(n_docs=500, n_queries=100),\n",
        "    \"nfcorpus\":dict(n_docs=1000, n_queries=150),\n",
        "}\n",
        "\n",
        "KS = (5, 10, 20)\n",
        "RECALL_AT = 50\n",
        "\n",
        "def load_subset(ds_name: str, n_docs: int, n_queries: int):\n",
        "    # Reusa a funÃ§Ã£o jÃ¡ criada no notebook:\n",
        "    docs, queries, qrels, doc_texts = load_subset_dataset(ds_name, n_docs=n_docs, n_queries=n_queries)\n",
        "    return dict(docs=docs, queries=queries, qrels=qrels, doc_texts=doc_texts)\n",
        "\n",
        "def eval_fixed(ds_name: str, cfg: dict, n_docs: int, n_queries: int, ks=KS, recall_at=RECALL_AT):\n",
        "    print(f\"\\n=== {ds_name.upper()} | subset: {n_docs} docs, {n_queries} queries ===\")\n",
        "    data = load_subset(ds_name, n_docs=n_docs, n_queries=n_queries)\n",
        "\n",
        "    ner_cfg = NERConfig(\n",
        "        backend=cfg[\"backend\"],\n",
        "        model=cfg[\"model\"],\n",
        "        use_noun_chunks=cfg[\"noun_chunks\"],\n",
        "        batch_size=16,\n",
        "        n_process=1,\n",
        "        allowed_labels=None,\n",
        "    )\n",
        "    enc = EntityEncoderReal(\n",
        "        graph_model_name=GRAPH_MODEL,\n",
        "        device=\"cpu\",\n",
        "        ner=ner_cfg,\n",
        "        min_df=cfg[\"min_df\"],\n",
        "        max_entities_per_text=cfg[\"max_entities\"],\n",
        "        cache=CacheConfig(artifact_dir=None, force_rebuild=True),\n",
        "    )\n",
        "    if not verify_ner_backend(enc, cfg[\"backend\"]):\n",
        "        print(\"  âš ï¸ Fallback no NER â€” abortando este dataset.\")\n",
        "        return None\n",
        "\n",
        "    # Fit IDF das entidades no subset maior\n",
        "    print(\"  Fit NER+IDF...\")\n",
        "    enc.fit(data[\"doc_texts\"])\n",
        "\n",
        "    # Retriever com mesmos params\n",
        "    retr = GraphRetriever(\n",
        "        graph_model_name=GRAPH_MODEL,\n",
        "        device=\"cpu\",\n",
        "        ner_backend=cfg[\"backend\"],\n",
        "        ner_model=cfg[\"model\"],\n",
        "        ner_use_noun_chunks=cfg[\"noun_chunks\"],\n",
        "        ner_batch_size=16,\n",
        "        ner_n_process=1,\n",
        "        min_df=cfg[\"min_df\"],\n",
        "        entity_artifact_dir=None,\n",
        "        entity_force_rebuild=True,\n",
        "    )\n",
        "\n",
        "    print(\"  Build index...\")\n",
        "    retr.build_index(data[\"docs\"])\n",
        "\n",
        "    # Precisamos recuperar atÃ© max(RECALL_AT, max(KS))\n",
        "    topk_needed = max(recall_at, max(ks))\n",
        "    print(f\"  Retrieve top-{topk_needed}...\")\n",
        "    preds = retr.retrieve(data[\"queries\"], k=topk_needed)\n",
        "\n",
        "    # MÃ©tricas em mÃºltiplos @k\n",
        "    print(\"  Avaliando mÃ©tricas...\")\n",
        "    m = evaluate_predictions(preds, data[\"qrels\"], ks=ks)\n",
        "    # Recall@50\n",
        "    # Se evaluate_predictions jÃ¡ incluir Recall para k=RECALL_AT, Ã³timo; se nÃ£o, recompute:\n",
        "    if recall_at not in ks:\n",
        "        m_extra = evaluate_predictions(preds, data[\"qrels\"], ks=(recall_at,))\n",
        "        recall50 = float(m_extra[m_extra[\"k\"] == recall_at][\"Recall\"].iloc[0])\n",
        "    else:\n",
        "        recall50 = float(m[m[\"k\"] == recall_at][\"Recall\"].iloc[0])\n",
        "\n",
        "    # Tabela amigÃ¡vel\n",
        "    tbl = (m[[\"k\",\"nDCG\",\"MRR\",\"Recall\",\"Precision\"]]\n",
        "           .sort_values(\"k\")\n",
        "           .reset_index(drop=True))\n",
        "    print(\"\\nMÃ©tricas por @k:\")\n",
        "    with pd.option_context(\"display.max_columns\", None):\n",
        "        print(tbl.round(4).to_string(index=False))\n",
        "    print(f\"\\nRecall@{recall_at}: {recall50:.4f}\")\n",
        "\n",
        "    return dict(metrics=tbl, recall_at_k=recall50)\n",
        "\n",
        "# Rodar por dataset com as configs vencedoras\n",
        "results_bigger = {}\n",
        "for ds in [\"scifact\", \"fiqa\", \"nfcorpus\"]:\n",
        "    cfg = BEST[ds]\n",
        "    sizes = BIGGER[ds]\n",
        "    res = eval_fixed(ds, cfg, n_docs=sizes[\"n_docs\"], n_queries=sizes[\"n_queries\"], ks=KS, recall_at=RECALL_AT)\n",
        "    results_bigger[ds] = res\n",
        "\n",
        "print(\"\\n=== Resumo nDCG@10 e Recall@50 (subset maior) ===\")\n",
        "summary_rows = []\n",
        "for ds, res in results_bigger.items():\n",
        "    if not res:\n",
        "        summary_rows.append(dict(dataset=ds, nDCG10=None, Recall50=None))\n",
        "        continue\n",
        "    nDCG10 = float(res[\"metrics\"].loc[res[\"metrics\"][\"k\"]==10, \"nDCG\"].iloc[0])\n",
        "    summary_rows.append(dict(dataset=ds, nDCG10=nDCG10, Recall50=res[\"recall_at_k\"]))\n",
        "df_summary = pd.DataFrame(summary_rows)\n",
        "print(df_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SciFact: Grafo funciona bem em escala (nDCG@10=0.642, Recall@50=0.90). ConclusÃ£o: NER biomÃ©dico + parÃ¢metros escolhidos generalizam.\n",
        "\n",
        "FIQA: Queda forte (nDCG@10=0.131, Recall@50=0.357). ConclusÃ£o: com mais dados, a cobertura/precisÃ£o de entidades cai; o slice de grafo nÃ£o sustenta domÃ­nio financeiro sÃ³ com spaCy genÃ©rico.\n",
        "\n",
        "NFCorpus: Muito baixo (nDCG@10=0.093, Recall@50=0.052). ConclusÃ£o: desalinhamento de entidade/consulta; grafo isolado tem pouca utilidade aqui."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TOP-K + SOFTMAX | SCIFACT ===\n",
            "ðŸ“Š SCIFACT: 800 docs, 150 queries, 171 qrels\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF (base)...\n",
            "  >> top_k=10, softmax=False\n",
            "     nDCG@10=0.5138 | Recall@50=0.7984\n",
            "  >> top_k=10, softmax=True\n",
            "     nDCG@10=0.3142 | Recall@50=0.5443\n",
            "  >> top_k=20, softmax=False\n",
            "     nDCG@10=0.5375 | Recall@50=0.8451\n",
            "  >> top_k=20, softmax=True\n",
            "     nDCG@10=0.3142 | Recall@50=0.5443\n",
            "  >> top_k=40, softmax=False\n",
            "     nDCG@10=0.5458 | Recall@50=0.8803\n",
            "  >> top_k=40, softmax=True\n",
            "     nDCG@10=0.3142 | Recall@50=0.5443\n",
            "\n",
            "Resultados (ordenado por nDCG@10):\n",
            " top_k  softmax  nDCG5  nDCG10  nDCG20  Recall50\n",
            "    40    False 0.5150  0.5458  0.5724    0.8803\n",
            "    20    False 0.5075  0.5375  0.5668    0.8451\n",
            "    10    False 0.4853  0.5138  0.5329    0.7984\n",
            "    10     True 0.3054  0.3142  0.3342    0.5443\n",
            "    20     True 0.3054  0.3142  0.3342    0.5443\n",
            "    40     True 0.3054  0.3142  0.3342    0.5443\n",
            "\n",
            "=== TOP-K + SOFTMAX | FIQA ===\n",
            "ðŸ“Š FIQA: 800 docs, 150 queries, 398 qrels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thiago/Documents/GitHub/hybrid-retrieval/.venv/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NER carregado: spacy | modelo: core_web_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF (base)...\n",
            "  >> top_k=10, softmax=False\n",
            "     nDCG@10=0.1120 | Recall@50=0.2574\n",
            "  >> top_k=10, softmax=True\n",
            "     nDCG@10=0.1059 | Recall@50=0.2272\n",
            "  >> top_k=20, softmax=False\n",
            "     nDCG@10=0.1126 | Recall@50=0.2591\n",
            "  >> top_k=20, softmax=True\n",
            "     nDCG@10=0.1058 | Recall@50=0.2272\n",
            "  >> top_k=40, softmax=False\n",
            "     nDCG@10=0.1125 | Recall@50=0.2607\n",
            "  >> top_k=40, softmax=True\n",
            "     nDCG@10=0.1058 | Recall@50=0.2272\n",
            "\n",
            "Resultados (ordenado por nDCG@10):\n",
            " top_k  softmax  nDCG5  nDCG10  nDCG20  Recall50\n",
            "    20    False 0.1030  0.1126  0.1244    0.2591\n",
            "    40    False 0.1030  0.1125  0.1250    0.2607\n",
            "    10    False 0.1025  0.1120  0.1226    0.2574\n",
            "    10     True 0.1012  0.1059  0.1147    0.2272\n",
            "    20     True 0.1002  0.1058  0.1146    0.2272\n",
            "    40     True 0.1002  0.1058  0.1146    0.2272\n",
            "\n",
            "=== TOP-K + SOFTMAX | NFCORPUS ===\n",
            "ðŸ“Š NFCORPUS: 1500 docs, 200 queries, 9488 qrels\n",
            "âœ“ NER carregado: scispacy | modelo: core_sci_md | pipes: ['tok2vec', 'attribute_ruler', 'ner']\n",
            "  Fit NER+IDF (base)...\n",
            "  >> top_k=10, softmax=False\n",
            "     nDCG@10=0.1269 | Recall@50=0.0576\n",
            "  >> top_k=10, softmax=True\n",
            "     nDCG@10=0.0991 | Recall@50=0.0406\n",
            "  >> top_k=20, softmax=False\n",
            "     nDCG@10=0.1268 | Recall@50=0.0586\n",
            "  >> top_k=20, softmax=True\n",
            "     nDCG@10=0.0992 | Recall@50=0.0406\n",
            "  >> top_k=40, softmax=False\n",
            "     nDCG@10=0.1272 | Recall@50=0.0578\n",
            "  >> top_k=40, softmax=True\n",
            "     nDCG@10=0.0992 | Recall@50=0.0406\n",
            "\n",
            "Resultados (ordenado por nDCG@10):\n",
            " top_k  softmax  nDCG5  nDCG10  nDCG20  Recall50\n",
            "    40    False 0.1497  0.1272  0.1140    0.0578\n",
            "    10    False 0.1442  0.1269  0.1126    0.0576\n",
            "    20    False 0.1473  0.1268  0.1143    0.0586\n",
            "    20     True 0.1197  0.0992  0.0840    0.0406\n",
            "    40     True 0.1197  0.0992  0.0840    0.0406\n",
            "    10     True 0.1191  0.0991  0.0840    0.0406\n"
          ]
        }
      ],
      "source": [
        "# === Top-k entidades + Softmax de pesos (por dataset com melhores configs) ===\n",
        "import faiss\n",
        "from math import exp\n",
        "from src.encoders.encoders import l2norm\n",
        "\n",
        "# Configs vencedoras (ajuste se mudar)\n",
        "BEST = {\n",
        "    \"scifact\": dict(backend=\"scispacy\", model=\"en_core_sci_md\",  min_df=1, noun_chunks=False, max_entities=128),\n",
        "    \"fiqa\":    dict(backend=\"spacy\",    model=\"en_core_web_md\",  min_df=1, noun_chunks=False, max_entities=256),  # amplia para mais cobertura\n",
        "    \"nfcorpus\":dict(backend=\"scispacy\", model=\"en_core_sci_md\",  min_df=2, noun_chunks=False, max_entities=256),  # amplia para mais cobertura\n",
        "}\n",
        "\n",
        "TOPK_LIST = [10, 20, 40]        # top-k entidades por doc/query\n",
        "USE_SOFTMAX_LIST = [False, True] # comparar sem vs com softmax\n",
        "\n",
        "def _softmax(weights):\n",
        "    m = max(weights) if weights else 0.0\n",
        "    exps = [exp(w - m) for w in weights]\n",
        "    s = sum(exps) + 1e-12\n",
        "    return [e / s for e in exps]\n",
        "\n",
        "class EntityEncoderTopKSoftmax:\n",
        "    \"\"\"\n",
        "    Usa um EntityEncoderReal jÃ¡ 'fit' (ent2idf + _get_emb) e aplica:\n",
        "      - seleÃ§Ã£o top-k por score tf*idf\n",
        "      - pesos: softmax(scores) (ou normalizaÃ§Ã£o L1)\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, top_k=20, use_softmax=True):\n",
        "        self.base = base_encoder\n",
        "        self.top_k = int(top_k)\n",
        "        self.use_softmax = bool(use_softmax)\n",
        "        self.dim = int(self.base.dim)\n",
        "\n",
        "    def encode_text(self, text: str) -> np.ndarray:\n",
        "        ents = self.base._extract_entities_batch([text or \"\"])[0]\n",
        "        if not ents:\n",
        "            return np.zeros(self.dim, dtype=np.float32)\n",
        "\n",
        "        # TF\n",
        "        tf = {}\n",
        "        for e in ents:\n",
        "            if e in self.base.ent2idf:\n",
        "                tf[e] = tf.get(e, 0) + 1\n",
        "\n",
        "        if not tf:\n",
        "            return np.zeros(self.dim, dtype=np.float32)\n",
        "\n",
        "        # Scores tf*idf\n",
        "        scored = [(e, tf[e] * self.base.ent2idf[e]) for e in tf.keys()]\n",
        "        scored.sort(key=lambda x: x[1], reverse=True)\n",
        "        if self.top_k > 0:\n",
        "            scored = scored[:self.top_k]\n",
        "\n",
        "        weights = [s for _, s in scored]\n",
        "        if self.use_softmax:\n",
        "            weights = _softmax(weights)\n",
        "        else:\n",
        "            s = sum(weights) + 1e-12\n",
        "            weights = [w / s for w in weights]\n",
        "\n",
        "        acc = np.zeros(self.dim, dtype=np.float32)\n",
        "        for (e, _), w in zip(scored, weights):\n",
        "            acc += float(w) * self.base._get_emb(e)\n",
        "\n",
        "        return l2norm(acc)\n",
        "\n",
        "def build_index_and_eval(docs, doc_texts, queries, qrels, wrapper_encoder, ks=(5,10,20), recall_at=50):\n",
        "    # 1) Encode docs\n",
        "    doc_vecs = [wrapper_encoder.encode_text(t) for t in doc_texts]\n",
        "    doc_mat = np.vstack(doc_vecs).astype(np.float32)\n",
        "    doc_ids = [d.doc_id for d in docs]  # IDs reais que aparecem nos qrels\n",
        "\n",
        "    # 2) FAISS index\n",
        "    index = faiss.IndexFlatIP(wrapper_encoder.dim)\n",
        "    index.add(doc_mat)\n",
        "\n",
        "    # 3) Retrieve\n",
        "    topk_needed = max(recall_at, max(ks))\n",
        "    preds = {}\n",
        "    for q in queries:\n",
        "        qv = wrapper_encoder.encode_text(q.text).reshape(1, -1).astype(np.float32)\n",
        "        scores, idx = index.search(qv, topk_needed)\n",
        "        ids = [doc_ids[i] for i in idx[0].tolist()]  # usa doc_ids reais\n",
        "        scs = scores[0].tolist()\n",
        "        preds[q.query_id] = list(zip(ids, scs))\n",
        "\n",
        "    # 4) AvaliaÃ§Ã£o\n",
        "    m = evaluate_predictions(preds, qrels, ks=ks)\n",
        "    m_extra = evaluate_predictions(preds, qrels, ks=(recall_at,))\n",
        "    recallX = float(m_extra[m_extra[\"k\"] == recall_at][\"Recall\"].iloc[0])\n",
        "\n",
        "    # (opcional) sanity check de overlap\n",
        "    # rel_ids = set(qrels[\"doc_id\"].unique())\n",
        "    # pred_ids_any = set(x for lst in preds.values() for x,_ in lst)\n",
        "    # print(\"Overlap doc_ids:\", len(rel_ids & pred_ids_any))\n",
        "\n",
        "    return m, recallX\n",
        "\n",
        "def run_topk_softmax_experiment(ds_name: str, big_n_docs: int, big_n_queries: int):\n",
        "    print(f\"\\n=== TOP-K + SOFTMAX | {ds_name.upper()} ===\")\n",
        "    # Carregar subset maior (funÃ§Ã£o jÃ¡ existente no notebook)\n",
        "    docs, queries, qrels, doc_texts = load_subset_dataset(ds_name, n_docs=big_n_docs, n_queries=big_n_queries)\n",
        "\n",
        "    cfg = BEST[ds_name]\n",
        "    # Preparar base encoder\n",
        "    ner_cfg = NERConfig(\n",
        "        backend=cfg[\"backend\"],\n",
        "        model=cfg[\"model\"],\n",
        "        use_noun_chunks=cfg[\"noun_chunks\"],\n",
        "        batch_size=16,\n",
        "        n_process=1,\n",
        "        allowed_labels=None,\n",
        "    )\n",
        "    base_enc = EntityEncoderReal(\n",
        "        graph_model_name=GRAPH_MODEL,\n",
        "        device=\"cpu\",\n",
        "        ner=ner_cfg,\n",
        "        min_df=cfg[\"min_df\"],\n",
        "        max_entities_per_text=cfg[\"max_entities\"],\n",
        "        cache=CacheConfig(artifact_dir=None, force_rebuild=False),\n",
        "    )\n",
        "    if not verify_ner_backend(base_enc, cfg[\"backend\"]):\n",
        "        print(\"  âš ï¸ Fallback no NER â€” abortando.\")\n",
        "        return None\n",
        "\n",
        "    print(\"  Fit NER+IDF (base)...\")\n",
        "    base_enc.fit(doc_texts)\n",
        "\n",
        "    rows = []\n",
        "    for top_k in TOPK_LIST:\n",
        "        for use_softmax in USE_SOFTMAX_LIST:\n",
        "            print(f\"  >> top_k={top_k}, softmax={use_softmax}\")\n",
        "            wrap = EntityEncoderTopKSoftmax(base_enc, top_k=top_k, use_softmax=use_softmax)\n",
        "            # dentro do loop top_k/use_softmax:\n",
        "            m, recall50 = build_index_and_eval(\n",
        "                docs=docs,\n",
        "                doc_texts=doc_texts,\n",
        "                queries=queries,\n",
        "                qrels=qrels,\n",
        "                wrapper_encoder=wrap,\n",
        "                ks=(5,10,20),\n",
        "                recall_at=50\n",
        "            )\n",
        "            row = dict(top_k=top_k, softmax=use_softmax,\n",
        "                       nDCG5=float(m[m['k']==5]['nDCG'].iloc[0]),\n",
        "                       nDCG10=float(m[m['k']==10]['nDCG'].iloc[0]),\n",
        "                       nDCG20=float(m[m['k']==20]['nDCG'].iloc[0]),\n",
        "                       Recall50=recall50)\n",
        "            rows.append(row)\n",
        "            print(f\"     nDCG@10={row['nDCG10']:.4f} | Recall@50={row['Recall50']:.4f}\")\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values([\"nDCG10\",\"Recall50\"], ascending=False)\n",
        "    print(\"\\nResultados (ordenado por nDCG@10):\")\n",
        "    with pd.option_context(\"display.max_columns\", None):\n",
        "        print(df.round(4).to_string(index=False))\n",
        "    return df\n",
        "\n",
        "# Tamanhos maiores (ajuste se quiser)\n",
        "BIG = {\"scifact\": (800, 150), \"fiqa\": (800, 150), \"nfcorpus\": (1500, 200)}\n",
        "\n",
        "dfs_topk = {}\n",
        "for ds in [\"scifact\", \"fiqa\", \"nfcorpus\"]:\n",
        "    n_docs, n_queries = BIG[ds]\n",
        "    dfs_topk[ds] = run_topk_softmax_experiment(ds, big_n_docs=n_docs, big_n_queries=n_queries)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
