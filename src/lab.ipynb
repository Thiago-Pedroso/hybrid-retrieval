{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c900cb8",
   "metadata": {},
   "source": [
    "# üî¨ Lab: Valida√ß√£o dos Retrievers Individuais\n",
    "\n",
    "Este notebook demonstra **passo a passo** como funcionam os tr√™s tipos de retrieval implementados no projeto, com √™nfase especial no **retriever de grafo** (entidades + embeddings).\n",
    "\n",
    "## Objetivos\n",
    "1. **TF-IDF Retriever**: Entender retrieval baseado em sobreposi√ß√£o lexical\n",
    "2. **Dense Retriever**: Compreender embeddings sem√¢nticos (MiniLM vs BGE)\n",
    "3. **Graph Retriever**: Explorar em profundidade a extra√ß√£o de entidades, IDF e agrega√ß√£o ponderada\n",
    "\n",
    "Usaremos um mini-corpus de 5 documentos e 3 queries para valida√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0b610",
   "metadata": {},
   "source": [
    "## üì¶ Setup: Imports e Configura√ß√£o do Ambiente\n",
    "\n",
    "Primeiro, garantimos que o Python encontra o reposit√≥rio e importamos as depend√™ncias necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defff65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /teamspace/studios/this_studio/hybrid-retrieval\n"
     ]
    }
   ],
   "source": [
    "# Se estiver em um ambiente limpo, descomente conforme necess√°rio:\n",
    "# %pip install -U sentence-transformers transformers torch scikit-learn spacy scispacy\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "while repo_root != repo_root.parent and repo_root.name != \"hybrid-retrieval\":\n",
    "    repo_root = repo_root.parent\n",
    "repo_root_str = str(repo_root)\n",
    "if repo_root_str not in sys.path:\n",
    "    sys.path.insert(0, repo_root_str)\n",
    "\n",
    "print(\"Repo root:\", repo_root)\n",
    "\n",
    "# Imports dos schemas do projeto\n",
    "from src.datasets.schema import Document, Query\n",
    "\n",
    "# Silencia warnings de modelos\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb14b44",
   "metadata": {},
   "source": [
    "## üìö Cria√ß√£o do Mini-Corpus\n",
    "\n",
    "Exemplos:\n",
    "\n",
    "Podemos criar 5 documentos com temas variados para testar os diferentes comportamentos dos retrievers:\n",
    "- **D1**: COVID-19 e vacinas (dom√≠nio m√©dico, entidades: \"COVID-19\", \"mRNA vaccines\")\n",
    "- **D2**: Mercados financeiros (dom√≠nio financeiro, entidades: \"equity market\", \"US economy\")\n",
    "- **D3**: Graph Neural Networks (dom√≠nio t√©cnico, entidades: \"GNNs\", \"entity classification\")\n",
    "- **D4**: Nutri√ß√£o (dom√≠nio sa√∫de, entidades: \"apples\", \"fiber\", \"vitamins\")\n",
    "- **D5**: Large Language Models (dom√≠nio ML, entidades: \"MiniLM\", \"BGE\")\n",
    "\n",
    "E 3 queries que exploram diferentes aspectos:\n",
    "- **Q1**: Busca sobre efic√°cia de vacinas (termos relacionados a D1)\n",
    "- **Q2**: Busca sobre impacto de taxas de juros (relacionada a D2)\n",
    "- **Q3**: Busca sobre embeddings de entidades e grafos (relacionada a D3 e D5)\n",
    "\n",
    "Segue uma expans√£o dessa ideia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6346c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Corpus: 24 documentos\n",
      "‚úì Queries: 5 consultas\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.schema import Document, Query\n",
    "\n",
    "docs = [\n",
    "    # ‚Äî Ci√™ncia / Biom√©dico ‚Äî\n",
    "    Document(doc_id=\"B1\", title=\"COVID-19 mRNA vaccines\", text=\"Clinical trials show efficacy of mRNA vaccines against COVID-19.\"),\n",
    "    Document(doc_id=\"B2\", title=\"mRNA vaccine safety profile\", text=\"Adverse effects and safety profile of mRNA COVID-19 vaccines.\"),\n",
    "    Document(doc_id=\"B3\", title=\"SARS-CoV-2 variants\", text=\"Variants of concern and vaccine effectiveness in real-world evidence.\"),\n",
    "    Document(doc_id=\"B4\", title=\"Clinical trials methodology\", text=\"Randomized controlled trials for vaccines and therapies.\"),\n",
    "    Document(doc_id=\"B5\", title=\"Long COVID studies\", text=\"Long-term cardiovascular effects following COVID-19 infection.\"),\n",
    "\n",
    "    # ‚Äî Sa√∫de / Nutri√ß√£o (NFCorpus-like) ‚Äî\n",
    "    Document(doc_id=\"N1\", title=\"Apples and dietary fiber\", text=\"Apples provide soluble fiber and vitamins that reduce health risks.\"),\n",
    "    Document(doc_id=\"N2\", title=\"Mediterranean diet\", text=\"Lower cardiovascular risk associated with Mediterranean diet.\"),\n",
    "    Document(doc_id=\"N3\", title=\"Vitamin D supplementation\", text=\"Vitamin D reduces risk of bone fractures in elderly population.\"),\n",
    "    Document(doc_id=\"N4\", title=\"Fiber and gut microbiome\", text=\"Dietary fiber improves gut microbiome and metabolic health.\"),\n",
    "    Document(doc_id=\"N5\", title=\"Sugar intake guidelines\", text=\"High sugar intake increases obesity and diabetes risk.\"),\n",
    "\n",
    "    # ‚Äî Finan√ßas (FIQA-like) ‚Äî\n",
    "    Document(doc_id=\"F1\", title=\"Interest rates and equity volatility\", text=\"Federal Reserve policy impacts equity market volatility and valuations.\"),\n",
    "    Document(doc_id=\"F2\", title=\"US economy outlook\", text=\"US CPI and interest rates drive consumer spending and growth.\"),\n",
    "    Document(doc_id=\"F3\", title=\"NASDAQ and tech stocks\", text=\"NASDAQ index rallies as AI revenues beat expectations.\"),\n",
    "    Document(doc_id=\"F4\", title=\"S&P 500 valuation\", text=\"S&P 500 price-to-earnings expands as rates stabilize.\"),\n",
    "    Document(doc_id=\"F5\", title=\"Dow Jones and dividends\", text=\"Dividend yields support Dow Jones performance amid rate cuts.\"),\n",
    "\n",
    "    # ‚Äî ML / IR / Grafos ‚Äî\n",
    "    Document(doc_id=\"M1\", title=\"Entity embeddings for retrieval\", text=\"BGE and MiniLM embeddings improve retrieval and reranking.\"),\n",
    "    Document(doc_id=\"M2\", title=\"Graph neural networks\", text=\"GNNs for entity classification and link prediction in knowledge graphs.\"),\n",
    "    Document(doc_id=\"M3\", title=\"Hybrid retrieval (dense+lexical+graph)\", text=\"Tri-modal fusion with TF-IDF, semantic and entity graph signals.\"),\n",
    "    Document(doc_id=\"M4\", title=\"RAG pipelines\", text=\"Retrieval augmented generation with reranking and hallucination control.\"),\n",
    "    Document(doc_id=\"M5\", title=\"Vector databases\", text=\"FAISS IVFPQ indexing for large-scale nearest neighbor search.\"),\n",
    "\n",
    "    # ‚Äî Pontes entre dom√≠nios (para DF > 1 em termos transversais) ‚Äî\n",
    "    Document(doc_id=\"X1\", title=\"Cardiovascular risk and diet\", text=\"Mediterranean diet and apples reduce cardiovascular risk.\"),\n",
    "    Document(doc_id=\"X2\", title=\"COVID-19 and US economy\", text=\"COVID-19 shocks affect US labor market and consumer demand.\"),\n",
    "    Document(doc_id=\"X3\", title=\"AI revenues and S&P 500\", text=\"AI-related revenues boost S&P 500 and NASDAQ tech valuations.\"),\n",
    "    Document(doc_id=\"X4\", title=\"Clinical trials and graph methods\", text=\"Graph-based methods assist clinical trials entity linking.\"),\n",
    "]\n",
    "\n",
    "queries = [\n",
    "    Query(query_id=\"Q1\", text=\"Are mRNA vaccines effective against COVID-19?\"),\n",
    "    Query(query_id=\"Q2\", text=\"How do interest rates impact equity volatility and valuations?\"),\n",
    "    Query(query_id=\"Q3\", text=\"Entity embeddings and graph-based retrieval methods in knowledge graphs\"),\n",
    "    Query(query_id=\"Q4\", text=\"Do apples and Mediterranean diet reduce cardiovascular risk?\"),\n",
    "    Query(query_id=\"Q5\", text=\"Are AI-related revenues influencing NASDAQ and S&P 500?\"),\n",
    "]\n",
    "\n",
    "print(f\"‚úì Corpus: {len(docs)} documentos\")\n",
    "print(f\"‚úì Queries: {len(queries)} consultas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef899f",
   "metadata": {},
   "source": [
    "---\n",
    "# üî§ Parte 1: TF-IDF Retriever (Sinal Lexical)\n",
    "\n",
    "## O que √© TF-IDF?\n",
    "- **Term Frequency (TF)**: Frequ√™ncia do termo no documento\n",
    "- **Inverse Document Frequency (IDF)**: Penaliza termos comuns no corpus\n",
    "- **Vetor TF-IDF**: Cada documento √© representado como um vetor esparso de tamanho = vocabul√°rio\n",
    "\n",
    "## Como funciona?\n",
    "1. **Fit**: Constr√≥i vocabul√°rio do corpus e calcula IDF para cada termo\n",
    "2. **Transform**: Converte documento ‚Üí vetor TF-IDF normalizado (L2)\n",
    "3. **Busca**: Similaridade por inner-product (equivalente a cosseno ap√≥s normaliza√ß√£o)\n",
    "\n",
    "## Vantagens\n",
    "‚úì R√°pido e interpret√°vel  \n",
    "‚úì Bom para matching exato de termos  \n",
    "\n",
    "## Limita√ß√µes\n",
    "‚úó N√£o captura sin√¥nimos ou par√°frases  \n",
    "‚úó Sens√≠vel a varia√ß√µes morfol√≥gicas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bfc65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Construindo √≠ndice TF-IDF...\n",
      "2025-10-30 00:38:50 | INFO     | retriever.tfidf | [tfidf_faiss.py:66] | üöÄ Building TF-IDF Index (24 documentos)\n",
      "2025-10-30 00:38:50 | INFO     | retriever.tfidf | [logging.py:199] | ‚è±Ô∏è  Fit TF-IDF no corpus - iniciando...\n",
      "2025-10-30 00:38:50 | INFO     | tfidf.vectorizer | [logging.py:199] | ‚è±Ô∏è  Fit TF-IDF - iniciando...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 00:38:52 | INFO     | tfidf.vectorizer | [logging.py:220] | ‚úì Fit TF-IDF - conclu√≠do em \u001b[32m1.38s\u001b[0m\n",
      "2025-10-30 00:38:52 | INFO     | tfidf.vectorizer | [tfidf_vectorizer.py:19] | ‚úì TF-IDF fitted: vocab_size=41\n",
      "2025-10-30 00:38:52 | INFO     | retriever.tfidf | [logging.py:220] | ‚úì Fit TF-IDF no corpus - conclu√≠do em \u001b[32m1.39s\u001b[0m\n",
      "2025-10-30 00:38:52 | INFO     | retriever.tfidf | [logging.py:199] | ‚è±Ô∏è  Encoding documents (TF-IDF) - iniciando...\n",
      "2025-10-30 00:38:52 | INFO     | retriever.tfidf | [logging.py:220] | ‚úì Encoding documents (TF-IDF) - conclu√≠do em \u001b[32m6.6ms\u001b[0m\n",
      "2025-10-30 00:38:52 | INFO     | retriever.tfidf | [logging.py:199] | ‚è±Ô∏è  Construindo FAISS IndexFlatIP - iniciando...\n",
      "2025-10-30 00:38:52 | INFO     | retriever.tfidf | [logging.py:220] | ‚úì Construindo FAISS IndexFlatIP - conclu√≠do em \u001b[32m9.7ms\u001b[0m\n",
      "2025-10-30 00:38:52 | INFO     | retriever.tfidf | [tfidf_faiss.py:85] |   ‚úì FAISS IndexFlatIP: 24 vetores, dim=2000\n",
      "\n",
      "üîç Executando retrieval (top-3 por query)...\n",
      "\n",
      "üìä Query [Q1]: Are mRNA vaccines effective against COVID-19?\n",
      "  1. B1 (score=0.9198) - COVID-19 mRNA vaccines\n",
      "  2. B2 (score=0.7802) - mRNA vaccine safety profile\n",
      "  3. B5 (score=0.5067) - Long COVID studies\n",
      "\n",
      "üìä Query [Q2]: How do interest rates impact equity volatility and valuations?\n",
      "  1. F1 (score=0.8616) - Interest rates and equity volatility\n",
      "  2. F2 (score=0.4282) - US economy outlook\n",
      "  3. F5 (score=0.2362) - Dow Jones and dividends\n",
      "\n",
      "üìä Query [Q3]: Entity embeddings and graph-based retrieval methods in knowledge graphs\n",
      "  1. M2 (score=0.7676) - Graph neural networks\n",
      "  2. M3 (score=0.7580) - Hybrid retrieval (dense+lexical+graph)\n",
      "  3. M1 (score=0.5818) - Entity embeddings for retrieval\n",
      "\n",
      "üìä Query [Q4]: Do apples and Mediterranean diet reduce cardiovascular risk?\n",
      "  1. X1 (score=0.9471) - Cardiovascular risk and diet\n",
      "  2. N2 (score=0.7198) - Mediterranean diet\n",
      "  3. N1 (score=0.4091) - Apples and dietary fiber\n",
      "\n",
      "üìä Query [Q5]: Are AI-related revenues influencing NASDAQ and S&P 500?\n",
      "  1. X3 (score=0.9381) - AI revenues and S&P 500\n",
      "  2. F4 (score=0.6498) - S&P 500 valuation\n",
      "  3. F3 (score=0.5871) - NASDAQ and tech stocks\n"
     ]
    }
   ],
   "source": [
    "from src.retrievers.tfidf_faiss import TFIDFRetriever\n",
    "\n",
    "tfidf_r = TFIDFRetriever(\n",
    "    dim=2000,             # vocabul√°rio maior\n",
    "    min_df=2,             # filtra termos raros; DF>=2 para corpus ampliado\n",
    "    backend=\"sklearn\",\n",
    "    use_faiss=True,\n",
    "    artifact_dir=None,\n",
    "    index_name=\"tfidf.index\",\n",
    ")\n",
    "\n",
    "print(\"üîß Construindo √≠ndice TF-IDF...\")\n",
    "tfidf_r.build_index(docs)\n",
    "\n",
    "print(\"\\nüîç Executando retrieval (top-3 por query)...\")\n",
    "tfidf_results = tfidf_r.retrieve(queries, k=3)\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nüìä Query [{q.query_id}]: {q.text}\")\n",
    "    pairs = tfidf_results.get(q.query_id, [])\n",
    "    for rank, (doc_id, score) in enumerate(pairs, 1):\n",
    "        title = next(d.title for d in docs if d.doc_id == doc_id)\n",
    "        print(f\"  {rank}. {doc_id} (score={score:.4f}) - {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a7b88",
   "metadata": {},
   "source": [
    "### üìà An√°lise dos Resultados TF-IDF\n",
    "\n",
    "**Observe**:\n",
    "- Queries com **termos exatos** do corpus (ex: \"mRNA\", \"vaccines\", \"COVID\") ranqueiam bem documentos correspondentes\n",
    "- Queries com **par√°frases** (ex: \"effective\" vs \"efficacy\") podem ter scores mais baixos\n",
    "- O TF-IDF √© **lexical**: n√£o entende que \"interest rates\" e \"taxas de juros\" s√£o sin√¥nimos\n",
    "\n",
    "**Exemplo**: Q1 ranquea B1 no topo, pois compartilha \"mRNA\", \"vaccines\", \"COVID\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383d958",
   "metadata": {},
   "source": [
    "---\n",
    "# üß† Parte 2: Dense Retriever (Embeddings Sem√¢nticos)\n",
    "\n",
    "## O que √© Dense Retrieval?\n",
    "- Usa **modelos de linguagem** (ex: MiniLM, BGE) para gerar embeddings densos\n",
    "- Cada documento/query ‚Üí vetor cont√≠nuo de 384d (MiniLM) ou 1024d (BGE-Large)\n",
    "- Similaridade captura **significado sem√¢ntico**, n√£o apenas palavras exatas\n",
    "\n",
    "## Modelos comparados no paper\n",
    "| Modelo | Dimens√£o | Par√¢metros | Uso |\n",
    "|--------|----------|------------|-----|\n",
    "| **MiniLM-L6-v2** | 384 | 22M | R√°pido, eficiente |\n",
    "| **BGE-Large** | 1024 | 335M | Maior qualidade |\n",
    "\n",
    "## Por que MiniLM pode superar BGE no h√≠brido?\n",
    "O paper mostra que embeddings menores podem ter **melhor alinhamento com LLMs** durante o reranking (fen√¥meno chamado \"FAISS Hybrid Paradox\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a85cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Construindo √≠ndice denso com sentence-transformers/all-MiniLM-L6-v2...\n",
      "   Dimens√£o: 384d\n",
      "2025-10-30 00:38:59 | INFO     | retriever.dense | [dense_faiss.py:75] | üöÄ Building Dense Index (24 documentos)\n",
      "2025-10-30 00:38:59 | INFO     | retriever.dense | [logging.py:199] | ‚è±Ô∏è  Encoding documents - iniciando...\n",
      "2025-10-30 00:38:59 | INFO     | retriever.dense | [logging.py:220] | ‚úì Encoding documents - conclu√≠do em \u001b[32m7.0ms\u001b[0m\n",
      "2025-10-30 00:38:59 | INFO     | retriever.dense | [logging.py:199] | ‚è±Ô∏è  Construindo FAISS IndexFlatIP - iniciando...\n",
      "2025-10-30 00:38:59 | INFO     | retriever.dense | [logging.py:220] | ‚úì Construindo FAISS IndexFlatIP - conclu√≠do em \u001b[32m0.6ms\u001b[0m\n",
      "2025-10-30 00:38:59 | INFO     | retriever.dense | [dense_faiss.py:92] |   ‚úì FAISS IndexFlatIP: 24 vetores, dim=384\n",
      "\n",
      "üîç Executando retrieval (top-3 por query)...\n",
      "\n",
      "üìä Query [Q1]: Are mRNA vaccines effective against COVID-19?\n",
      "  1. B1 (score=0.7346) - COVID-19 mRNA vaccines\n",
      "  2. B2 (score=0.4246) - mRNA vaccine safety profile\n",
      "  3. X2 (score=0.3059) - COVID-19 and US economy\n",
      "\n",
      "üìä Query [Q2]: How do interest rates impact equity volatility and valuations?\n",
      "  1. F1 (score=0.6877) - Interest rates and equity volatility\n",
      "  2. F2 (score=0.2547) - US economy outlook\n",
      "  3. X3 (score=0.2017) - AI revenues and S&P 500\n",
      "\n",
      "üìä Query [Q3]: Entity embeddings and graph-based retrieval methods in knowledge graphs\n",
      "  1. M1 (score=0.5521) - Entity embeddings for retrieval\n",
      "  2. M2 (score=0.5244) - Graph neural networks\n",
      "  3. X4 (score=0.4226) - Clinical trials and graph methods\n",
      "\n",
      "üìä Query [Q4]: Do apples and Mediterranean diet reduce cardiovascular risk?\n",
      "  1. X1 (score=0.8762) - Cardiovascular risk and diet\n",
      "  2. N2 (score=0.5251) - Mediterranean diet\n",
      "  3. N1 (score=0.3420) - Apples and dietary fiber\n",
      "\n",
      "üìä Query [Q5]: Are AI-related revenues influencing NASDAQ and S&P 500?\n",
      "  1. X3 (score=0.7892) - AI revenues and S&P 500\n",
      "  2. F3 (score=0.3708) - NASDAQ and tech stocks\n",
      "  3. F4 (score=0.3686) - S&P 500 valuation\n"
     ]
    }
   ],
   "source": [
    "from src.retrievers.dense_faiss import DenseFaiss\n",
    "\n",
    "# Escolha do modelo (altere para testar)\n",
    "dense_model = \"sentence-transformers/all-MiniLM-L6-v2\"  \n",
    "# Alternativa: \"BAAI/bge-large-en-v1.5\"\n",
    "\n",
    "dense_r = DenseFaiss(\n",
    "    model_name=dense_model,\n",
    "    device=\"cuda:0\",              # Use \"cuda:0\" se tiver GPU dispon√≠vel\n",
    "    query_prefix=\"\",\n",
    "    doc_prefix=\"\",\n",
    "    use_faiss=True,\n",
    "    artifact_dir=None,\n",
    "    index_name=\"dense.index\",\n",
    ")\n",
    "\n",
    "print(f\"üîß Construindo √≠ndice denso com {dense_model}...\")\n",
    "print(f\"   Dimens√£o: {dense_r.dim}d\")\n",
    "dense_r.build_index(docs)\n",
    "\n",
    "print(\"\\nüîç Executando retrieval (top-3 por query)...\")\n",
    "dense_results = dense_r.retrieve(queries, k=3)\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nüìä Query [{q.query_id}]: {q.text}\")\n",
    "    pairs = dense_results.get(q.query_id, [])\n",
    "    for rank, (doc_id, score) in enumerate(pairs, 1):\n",
    "        doc = next(d for d in docs if d.doc_id == doc_id)\n",
    "        print(f\"  {rank}. {doc_id} (score={score:.4f}) - {doc.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef66b78",
   "metadata": {},
   "source": [
    "### üìà An√°lise dos Resultados Dense\n",
    "\n",
    "**Observe**:\n",
    "- Melhor captura de **sin√¥nimos** e **par√°frases** (ex: \"effective\" ‚âà \"efficacy\")\n",
    "- Scores geralmente mais **uniformes** do que TF-IDF (espa√ßo denso √© mais suave)\n",
    "- Pode ranquear documentos **tematicamente relacionados** mesmo sem overlap lexical\n",
    "\n",
    "**Experimento**: Troque para `\"BAAI/bge-large-en-v1.5\"` e compare os resultados!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82881cd",
   "metadata": {},
   "source": [
    "---\n",
    "# üï∏Ô∏è Parte 3: Graph Retriever (Entidades + Embeddings)\n",
    "\n",
    "## Vis√£o Geral\n",
    "O retriever de grafo implementa o **terceiro modo (g)** do paper:\n",
    "1. **Extra√ß√£o de Entidades**: Identifica \"nomes\" importantes no texto (pessoas, locais, termos t√©cnicos)\n",
    "2. **IDF de Entidades**: Calcula import√¢ncia relativa de cada entidade no corpus\n",
    "3. **Embedding de Entidades**: Cada entidade ‚Üí vetor denso (ex: BGE-Large 1024d)\n",
    "4. **Agrega√ß√£o TF-IDF**: Vetor do documento = Œ£ [TF(e) √ó IDF(e) √ó emb(e)]\n",
    "5. **Normaliza√ß√£o L2**: Vetor final √© normalizado para compara√ß√£o por cosseno\n",
    "\n",
    "## F√≥rmula\n",
    "\n",
    "g(text) = L2_norm( Œ£_{e ‚àà entities(text)} TF(e, text) √ó IDF(e) √ó embedding(e) )\n",
    "\n",
    "\n",
    "## Por que √© √∫til?\n",
    "- Captura **sinal estruturado** de entidades nomeadas\n",
    "- √ötil em dom√≠nios com **terminologia espec√≠fica** (medicina, finan√ßas, produtos)\n",
    "- Complementa sinais denso e lexical no h√≠brido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7a524",
   "metadata": {},
   "source": [
    "## üîç Passo 1: Extra√ß√£o de Entidades (NER unificado + regras leves)\n",
    "\n",
    "Agora usamos um √∫nico backbone NER para todos os dom√≠nios: **spaCy en_core_web_trf** (RoBERTa-base).\n",
    "Para ‚Äúvitaminar‚Äù a cobertura, adicionamos um EntityRuler com padr√µes leves:\n",
    "\n",
    "- Financeiro: ORG/MONEY_TERM b√°sicos (ex.: ‚ÄúFederal Reserve‚Äù, ‚Äúinterest rates‚Äù) e um padr√£o simples de TICKER (regex).\n",
    "- Biom√©dico: termos cient√≠ficos comuns (ex.: ‚ÄúCOVID-19‚Äù, ‚ÄúmRNA‚Äù, ‚Äúclinical trials‚Äù).\n",
    "- Al√©m disso, usamos noun chunks (sintagmas nominais), que ajudam em termos compostos.\n",
    "\n",
    "Isso busca equil√≠brio entre SciFact (ci√™ncia/biom√©dico), NFCorpus (sa√∫de/nutri√ß√£o) e FIQA (finan√ßas) sem manter tr√™s NERs diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b7dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Documento D1:\n",
      "COVID-19 mRNA vaccines Clinical trials show efficacy of mRNA vaccines against COVID-19.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Usando spaCy (transformer): en_core_web_trf\n",
      "\n",
      "üè∑Ô∏è  Entidades Nomeadas Detectadas:\n",
      "   - 'COVID-19' [DISEASE_TERM]\n",
      "   - 'mRNA' [BIOMED_TERM]\n",
      "   - 'mRNA' [BIOMED_TERM]\n",
      "   - 'COVID-19' [DISEASE_TERM]\n",
      "\n",
      "üì¶ Noun Chunks Detectados:\n",
      "\n",
      "‚úì Total de entidades √∫nicas: 2\n",
      "  Entidades: ['covid-19', 'mrna']\n"
     ]
    }
   ],
   "source": [
    "# Extra√ß√£o de entidades com spaCy en_core_web_trf + EntityRuler (regras leves)\n",
    "# Se o modelo n√£o estiver instalado, voc√™ pode fazer:\n",
    "#   !python -m spacy download en_core_web_trf\n",
    "# Caso indispon√≠vel, cairemos para \"en_core_web_sm\".\n",
    "\n",
    "doc_text = docs[0].title + \" \" + docs[0].text\n",
    "print(f\"üìÑ Documento D1:\\n{doc_text}\\n\")\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        # mant√©m parser ativo para noun_chunks\n",
    "        nlp = spacy.load(\"en_core_web_trf\", disable=[\"tagger\", \"lemmatizer\"])\n",
    "        print(\"‚úì Usando spaCy (transformer): en_core_web_trf\")\n",
    "    except Exception:\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"lemmatizer\"])\n",
    "        print(\"‚úì Usando spaCy: en_core_web_sm\")\n",
    "\n",
    "    # Adiciona EntityRuler com padr√µes leves (finance/biomed) + um padr√£o simples de TICKER (regex)\n",
    "    before = \"ner\" if \"ner\" in nlp.pipe_names else None\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=before)\n",
    "    patterns = [\n",
    "        # Finance\n",
    "        {\"label\": \"ORG\", \"pattern\": \"Federal Reserve\"},\n",
    "        {\"label\": \"ORG\", \"pattern\": \"Fed\"},\n",
    "        {\"label\": \"ORG\", \"pattern\": \"Nasdaq\"},\n",
    "        {\"label\": \"ORG\", \"pattern\": \"Dow Jones\"},\n",
    "        {\"label\": \"ORG\", \"pattern\": \"S&P 500\"},\n",
    "        {\"label\": \"MONEY_TERM\", \"pattern\": \"interest rates\"},\n",
    "        {\"label\": \"MONEY_TERM\", \"pattern\": \"equity market\"},\n",
    "        # TICKER (regex super simples just for demo)\n",
    "        {\"label\": \"TICKER\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"^[A-Z]{1,5}$\"}}]},\n",
    "        # Biomed\n",
    "        {\"label\": \"DISEASE_TERM\", \"pattern\": \"COVID-19\"},\n",
    "        {\"label\": \"DISEASE_TERM\", \"pattern\": \"SARS-CoV-2\"},\n",
    "        {\"label\": \"BIOMED_TERM\", \"pattern\": \"mRNA\"},\n",
    "        {\"label\": \"BIOMED_TERM\", \"pattern\": \"clinical trials\"},\n",
    "    ]\n",
    "    ruler.add_patterns(patterns)\n",
    "\n",
    "    doc = nlp(doc_text)\n",
    "\n",
    "    # Entidades nomeadas (NER + regras)\n",
    "    entities = []\n",
    "    print(\"\\nüè∑Ô∏è  Entidades Nomeadas Detectadas:\")\n",
    "    for ent in doc.ents:\n",
    "        entities.append(ent.text.lower().strip())\n",
    "        print(f\"   - '{ent.text}' [{ent.label_}]\")\n",
    "\n",
    "    # Noun chunks\n",
    "    print(\"\\nüì¶ Noun Chunks Detectados:\")\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_text = chunk.text.lower().strip()\n",
    "        if chunk_text not in entities:\n",
    "            entities.append(chunk_text)\n",
    "        print(f\"   - '{chunk.text}'\")\n",
    "\n",
    "    print(f\"\\n‚úì Total de entidades √∫nicas: {len(set(entities))}\")\n",
    "    print(f\"  Entidades: {sorted(set(entities))}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  spaCy n√£o dispon√≠vel: {e}\")\n",
    "    print(\"   Usando fallback regex (detecta termos capitalizados e longos)\")\n",
    "\n",
    "    import re\n",
    "    pattern = re.compile(r\"[A-Za-z][A-Za-z0-9_\\-/\\.]{1,}\")\n",
    "    candidates = []\n",
    "    for tok in pattern.findall(doc_text):\n",
    "        if len(tok) >= 10 or tok[0].isupper():\n",
    "            candidates.append(tok.lower())\n",
    "    print(f\"\\n  Entidades detectadas (fallback): {sorted(set(candidates))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0aa3a",
   "metadata": {},
   "source": [
    "### üí° Interpreta√ß√£o da Extra√ß√£o (NER unificado + regras)\n",
    "\n",
    "- Backbone: `en_core_web_trf` (RoBERTa-base) com bom recall geral (ORG, PERSON, MONEY, DATE, GPE...).\n",
    "- Regras leves (EntityRuler):\n",
    "  - Finance: ‚ÄúFederal Reserve‚Äù, ‚Äúinterest rates‚Äù, ‚Äúequity market‚Äù, tickers simples.\n",
    "  - Biomed: ‚ÄúCOVID-19‚Äù, ‚ÄúSARS-CoV-2‚Äù, ‚ÄúmRNA‚Äù, ‚Äúclinical trials‚Äù.\n",
    "- Noun Chunks: sintagmas nominais como ‚ÄúmRNA vaccines‚Äù, ‚Äúinterest rates‚Äù.\n",
    "- Normaliza√ß√£o: lowercase, remo√ß√£o de pontua√ß√£o, m√≠nimo de 2 caracteres.\n",
    "\n",
    "Vantagem: um √∫nico NER robusto a m√∫ltiplos dom√≠nios com complementos m√≠nimos por regra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4650d",
   "metadata": {},
   "source": [
    "## üßÆ Passo 2: C√°lculo do IDF de Entidades\n",
    "\n",
    "Ap√≥s extrair entidades de **todos** os documentos, calculamos o IDF:\n",
    "\n",
    "IDF(e) = log((1 + N) / (1 + DF(e))) + 1.0\n",
    "\n",
    "\n",
    "Onde:\n",
    "- **N** = n√∫mero total de documentos\n",
    "- **DF(e)** = n√∫mero de documentos que cont√™m a entidade `e`\n",
    "\n",
    "**Intui√ß√£o**: Entidades raras (baixo DF) recebem maior peso; entidades comuns (alto DF) s√£o penalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6af267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Calculando IDF de Entidades no Corpus (min_df=2)\n",
      "\n",
      "üìä Top 15 Entidades por IDF (DF ‚â• 2):\n",
      "\n",
      "   mediterranean          | DF= 2 | IDF=3.1203\n",
      "   valuations             | DF= 2 | IDF=3.1203\n",
      "   us                     | DF= 2 | IDF=3.1203\n",
      "   nasdaq                 | DF= 2 | IDF=3.1203\n",
      "   ai                     | DF= 2 | IDF=3.1203\n",
      "   clinical               | DF= 3 | IDF=2.8326\n",
      "   cardiovascular         | DF= 3 | IDF=2.8326\n",
      "   covid-19               | DF= 4 | IDF=2.6094\n",
      "\n",
      "‚úì Entidades (DF ‚â• 2): 8 de 67 √∫nicas\n"
     ]
    }
   ],
   "source": [
    "# C√°lculo manual de DF/IDF com min_df=2 (opcional, para inspecionar)\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "print(\"üî¢ Calculando IDF de Entidades no Corpus (min_df=2)\\n\")\n",
    "\n",
    "def extract_entities_simple(text):\n",
    "    pattern = re.compile(r\"[A-Za-z][A-Za-z0-9_\\-/\\.]{1,}\")\n",
    "    entities = []\n",
    "    for tok in pattern.findall(text):\n",
    "        if len(tok) >= 10 or tok[0].isupper():\n",
    "            entities.append(tok.lower().strip(\".,;:()[]{}\"))\n",
    "    return [e for e in entities if len(e) >= 2]\n",
    "\n",
    "df = defaultdict(int)\n",
    "N = len(docs)\n",
    "\n",
    "for d in docs:\n",
    "    ents = set(extract_entities_simple((d.title or \"\") + \" \" + (d.text or \"\")))\n",
    "    for e in ents:\n",
    "        df[e] += 1\n",
    "\n",
    "# aplica min_df=2\n",
    "df2 = {e:c for e,c in df.items() if c >= 2}\n",
    "\n",
    "entity_idf = {e: (np.log((1+N)/(1+c)) + 1.0) for e,c in df2.items()}\n",
    "sorted_entities = sorted(entity_idf.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"üìä Top 15 Entidades por IDF (DF ‚â• 2):\\n\")\n",
    "for e, idf in sorted_entities[:15]:\n",
    "    print(f\"   {e:<22} | DF={df[e]:>2} | IDF={idf:.4f}\")\n",
    "print(f\"\\n‚úì Entidades (DF ‚â• 2): {len(entity_idf)} de {len(df)} √∫nicas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745656e",
   "metadata": {},
   "source": [
    "### üìà Interpreta√ß√£o do IDF\n",
    "\n",
    "**Entidades com IDF alto** (raras):\n",
    "- Aparecem em poucos documentos\n",
    "- S√£o mais **discriminativas** (ajudam a diferenciar documentos)\n",
    "\n",
    "**Entidades com IDF baixo** (comuns):\n",
    "- Aparecem em muitos documentos\n",
    "- S√£o menos √∫teis para distinguir conte√∫do\n",
    "- Exemplo: termos gen√©ricos que aparecem em m√∫ltiplos contextos\n",
    "\n",
    "**Por que isso importa?** \n",
    "O IDF pondera a contribui√ß√£o de cada entidade no vetor final, dando mais peso a termos discriminativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0706a2",
   "metadata": {},
   "source": [
    "## üéØ Passo 3: Embedding de Entidades\n",
    "\n",
    "Cada entidade √© transformada em um **vetor denso** usando um modelo HF (ex: BGE-Large).\n",
    "\n",
    "**Exemplo**: \n",
    "- Entidade: `\"mRNA vaccines\"`\n",
    "- Embedding: vetor de 1024 dimens√µes (se BGE-Large)\n",
    "\n",
    "**Por que embeddings de entidades?**\n",
    "- Captura **similaridade sem√¢ntica entre entidades** (ex: \"mRNA\" ‚âà \"RNA-based\")\n",
    "- Permite que entidades relacionadas contribuam de forma similar ao vetor do documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5648dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Gerando Embeddings de Entidades\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modelo: BAAI/bge-large-en-v1.5\n",
      "‚úì Dimens√£o: 1024d\n",
      "\n",
      "üìä Embeddings de Entidades (primeiras 5 dimens√µes):\n",
      "\n",
      "   mrna vaccines        ‚Üí [[0.0429553  0.00623018 0.02103916 0.0337704  0.00673586]...] || norm=1.0000\n",
      "   covid-19             ‚Üí [[-0.03450392 -0.00453843 -0.00358562  0.06227142  0.00305257]...] || norm=1.0000\n",
      "   equity market        ‚Üí [[-0.01458916  0.04924496 -0.02150347  0.01151251  0.00439941]...] || norm=1.0000\n",
      "   gnns                 ‚Üí [[-0.00744154 -0.00087572 -0.00218375 -0.01080718  0.0085467 ]...] || norm=1.0000\n",
      "\n",
      "‚úì Embeddings gerados e normalizados (L2 norm ‚âà 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Vamos ver como uma entidade √© transformada em embedding\n",
    "\n",
    "from src.encoders.encoders import HFSemanticEncoder, l2norm\n",
    "\n",
    "print(\"üß¨ Gerando Embeddings de Entidades\\n\")\n",
    "\n",
    "# Carrega encoder (mesmo usado no retriever de grafo)\n",
    "entity_encoder = HFSemanticEncoder(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",  # BGE-Large (1024d)\n",
    "    device=None,\n",
    ")\n",
    "\n",
    "print(f\"‚úì Modelo: {entity_encoder.model_name}\")\n",
    "print(f\"‚úì Dimens√£o: {entity_encoder.dim}d\\n\")\n",
    "\n",
    "# Embute algumas entidades exemplo\n",
    "sample_entities = [\"mrna vaccines\", \"covid-19\", \"equity market\", \"gnns\"]\n",
    "\n",
    "print(\"üìä Embeddings de Entidades (primeiras 5 dimens√µes):\\n\")\n",
    "embeddings = {}\n",
    "for ent in sample_entities:\n",
    "    emb = l2norm(entity_encoder.encode_text(ent, is_query=False))\n",
    "    embeddings[ent] = emb\n",
    "    norm = np.linalg.norm(emb)\n",
    "    print(f\"   {ent:<20} ‚Üí [{emb[:5]}...] || norm={norm:.4f}\")\n",
    "\n",
    "print(\"\\n‚úì Embeddings gerados e normalizados (L2 norm ‚âà 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba440d5",
   "metadata": {},
   "source": [
    "### üîó Similaridade entre Entidades\n",
    "\n",
    "Vamos calcular a **similaridade de cosseno** entre pares de entidades para verificar se o modelo captura rela√ß√µes sem√¢nticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc222348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Similaridade entre Entidades (cosseno):\n",
      "\n",
      "   'mrna vaccines' ‚Üî 'covid-19': 0.5725\n",
      "   'equity market' ‚Üî 'gnns': 0.4921\n",
      "   'mrna vaccines' ‚Üî 'equity market': 0.5086\n",
      "\n",
      "üí° Entidades semanticamente relacionadas t√™m similaridade maior!\n"
     ]
    }
   ],
   "source": [
    "# Calcula similaridade de cosseno entre pares de entidades\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    return float(np.dot(v1, v2))  # J√° normalizados (L2), ent√£o dot = cosseno\n",
    "\n",
    "print(\"üîó Similaridade entre Entidades (cosseno):\\n\")\n",
    "\n",
    "pairs = [\n",
    "    (\"mrna vaccines\", \"covid-19\"),      # relacionadas (dom√≠nio m√©dico)\n",
    "    (\"equity market\", \"gnns\"),          # n√£o relacionadas (finan√ßas vs ML)\n",
    "    (\"mrna vaccines\", \"equity market\"), # n√£o relacionadas (medicina vs finan√ßas)\n",
    "]\n",
    "\n",
    "for e1, e2 in pairs:\n",
    "    if e1 in embeddings and e2 in embeddings:\n",
    "        sim = cosine_sim(embeddings[e1], embeddings[e2])\n",
    "        print(f\"   '{e1}' ‚Üî '{e2}': {sim:.4f}\")\n",
    "\n",
    "print(\"\\nüí° Entidades semanticamente relacionadas t√™m similaridade maior!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe95c7fc",
   "metadata": {},
   "source": [
    "## üß© Passo 4: Agrega√ß√£o TF-IDF de Entidades\n",
    "\n",
    "Agora combinamos tudo para gerar o **vetor do documento**:\n",
    "\n",
    "g(doc) = L2_norm( Œ£_{e ‚àà doc} TF(e, doc) √ó IDF(e) √ó embedding(e) )\n",
    "\n",
    "\n",
    "Onde:\n",
    "- **TF(e, doc)** = frequ√™ncia da entidade no documento\n",
    "- **IDF(e)** = inverse document frequency (calculado no passo 2)\n",
    "- **embedding(e)** = vetor denso da entidade (calculado no passo 3)\n",
    "\n",
    "**Algoritmo**:\n",
    "1. Extrair entidades do documento\n",
    "2. Contar TF de cada entidade\n",
    "3. Para cada entidade: peso = TF √ó IDF\n",
    "4. Somar: vetor_final = Œ£ (peso √ó embedding)\n",
    "5. Normalizar L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e7eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Documento D1:\n",
      "COVID-19 mRNA vaccines Clinical trials show efficacy of mRNA vaccines against COVID-19.\n",
      "\n",
      "üè∑Ô∏è  Entidades extra√≠das: ['covid-19', 'clinical', 'covid-19']\n",
      "\n",
      "üî¢ Term Frequency (TF):\n",
      "   covid-19: 2\n",
      "   clinical: 1\n",
      "\n",
      "üßÆ Agrega√ß√£o TF-IDF √ó Embeddings:\n",
      "   covid-19             | TF=2 | IDF=2.6094 | weight=5.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clinical             | TF=1 | IDF=2.8326 | weight=2.8326\n",
      "\n",
      "‚úì Vetor final (primeiras 5 dims): [-0.03098487 -0.00815338 -0.00128427  0.05437236 -0.01989531]\n",
      "‚úì Norma L2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Vamos calcular manualmente o vetor de grafo para o documento D1\n",
    "\n",
    "doc_d1 = docs[0]\n",
    "text_d1 = (doc_d1.title or \"\") + \" \" + (doc_d1.text or \"\")\n",
    "print(f\"üìÑ Documento D1:\\n{text_d1}\\n\")\n",
    "\n",
    "# 1. Extrai entidades\n",
    "entities_d1 = extract_entities_simple(text_d1)\n",
    "print(f\"üè∑Ô∏è  Entidades extra√≠das: {entities_d1}\\n\")\n",
    "\n",
    "# 2. Conta TF\n",
    "from collections import Counter\n",
    "tf_d1 = Counter(entities_d1)\n",
    "print(f\"üî¢ Term Frequency (TF):\")\n",
    "for e, count in tf_d1.items():\n",
    "    print(f\"   {e}: {count}\")\n",
    "\n",
    "# 3. Calcula vetor agregado (manual)\n",
    "print(f\"\\nüßÆ Agrega√ß√£o TF-IDF √ó Embeddings:\")\n",
    "vec_d1 = np.zeros(entity_encoder.dim, dtype=np.float32)\n",
    "\n",
    "for e, tf in tf_d1.items():\n",
    "    if e in entity_idf:  # entidade conhecida no corpus\n",
    "        idf = entity_idf[e]\n",
    "        weight = tf * idf\n",
    "        \n",
    "        # Gera embedding da entidade (ou usa cache)\n",
    "        if e not in embeddings:\n",
    "            embeddings[e] = l2norm(entity_encoder.encode_text(e, is_query=False))\n",
    "        emb = embeddings[e]\n",
    "        \n",
    "        vec_d1 += weight * emb\n",
    "        print(f\"   {e:<20} | TF={tf} | IDF={idf:.4f} | weight={weight:.4f}\")\n",
    "\n",
    "# 4. Normaliza L2\n",
    "vec_d1 = l2norm(vec_d1)\n",
    "print(f\"\\n‚úì Vetor final (primeiras 5 dims): {vec_d1[:5]}\")\n",
    "print(f\"‚úì Norma L2: {np.linalg.norm(vec_d1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f708b",
   "metadata": {},
   "source": [
    "### üí° Interpreta√ß√£o da Agrega√ß√£o\n",
    "\n",
    "**Contribui√ß√£o de cada entidade**:\n",
    "- Entidades **frequentes** no documento (alto TF) contribuem mais\n",
    "- Entidades **raras** no corpus (alto IDF) t√™m maior peso relativo\n",
    "- Embedding captura o **significado sem√¢ntico** da entidade\n",
    "\n",
    "**Resultado final**:\n",
    "- Vetor denso de 1024d (se BGE-Large) normalizado\n",
    "- Representa o documento como uma **composi√ß√£o ponderada de suas entidades**\n",
    "- Permite compara√ß√£o por cosseno com queries que tamb√©m passam pelo mesmo processo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6965fd",
   "metadata": {},
   "source": [
    "## üöÄ Retriever de Grafo Completo (com NER unificado)\n",
    "\n",
    "Aqui usamos o `GraphRetriever` com backend NER = spaCy `en_core_web_trf`.\n",
    "Observa√ß√£o:\n",
    "- O c√≥digo de produ√ß√£o (classe `EntityEncoderReal`) j√° suporta EntityRuler e regras leves.\n",
    "- Em produ√ß√£o, essas regras podem ser ligadas via flags no `NERConfig` (no pipeline interno).\n",
    "- No laborat√≥rio acima, demonstramos como ‚Äúvitaminar‚Äù manualmente via spaCy para visualiza√ß√£o.\n",
    "\n",
    "O pipeline automatiza:\n",
    "1) Fit (extra√ß√£o + IDF)\n",
    "2) Build (vectoriza√ß√£o e index FAISS)\n",
    "3) Retrieve (query ‚Üí vetor de grafo ‚Üí busca por cosseno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5804c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Construindo √≠ndice de grafo...\n",
      "   Modelo: BAAI/bge-large-en-v1.5\n",
      "   Dimens√£o: 1024d\n",
      "2025-10-30 00:39:18 | INFO     | retriever.graph | [graph_faiss.py:91] | üöÄ Building Graph Index (24 documentos)\n",
      "2025-10-30 00:39:18 | INFO     | retriever.graph | [logging.py:199] | ‚è±Ô∏è  Fit GraphVectorizer no corpus - iniciando...\n",
      "2025-10-30 00:39:18 | INFO     | graph.vectorizer | [logging.py:199] | ‚è±Ô∏è  Fit Graph (NER + IDF) - iniciando...\n",
      "2025-10-30 00:39:19 | INFO     | graph.vectorizer | [logging.py:220] | ‚úì Fit Graph (NER + IDF) - conclu√≠do em \u001b[32m958.6ms\u001b[0m\n",
      "2025-10-30 00:39:19 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | ‚úì Graph fitted: dim=1024, ents=5\n",
      "2025-10-30 00:39:19 | INFO     | retriever.graph | [logging.py:220] | ‚úì Fit GraphVectorizer no corpus - conclu√≠do em \u001b[32m961.3ms\u001b[0m\n",
      "2025-10-30 00:39:19 | INFO     | retriever.graph | [logging.py:199] | ‚è±Ô∏è  Encoding documents (Graph) - iniciando...\n",
      "2025-10-30 00:39:30 | INFO     | retriever.graph | [logging.py:220] | ‚úì Encoding documents (Graph) - conclu√≠do em \u001b[32m11.17s\u001b[0m\n",
      "2025-10-30 00:39:30 | INFO     | retriever.graph | [logging.py:199] | ‚è±Ô∏è  Construindo FAISS IndexFlatIP - iniciando...\n",
      "2025-10-30 00:39:30 | INFO     | retriever.graph | [logging.py:220] | ‚úì Construindo FAISS IndexFlatIP - conclu√≠do em \u001b[32m0.7ms\u001b[0m\n",
      "2025-10-30 00:39:30 | INFO     | retriever.graph | [graph_faiss.py:111] |   ‚úì FAISS IndexFlatIP: 24 vetores, dim=1024\n",
      "\n",
      "üîç Executando retrieval (top-3 por query)...\n",
      "\n",
      "üìä Query [Q1]: Are mRNA vaccines effective against COVID-19?\n",
      "  1. B3 (score=0.0000) - SARS-CoV-2 variants\n",
      "  2. B2 (score=0.0000) - mRNA vaccine safety profile\n",
      "  3. B1 (score=0.0000) - COVID-19 mRNA vaccines\n",
      "\n",
      "üìä Query [Q2]: How do interest rates impact equity volatility and valuations?\n",
      "  1. B3 (score=0.0000) - SARS-CoV-2 variants\n",
      "  2. B2 (score=0.0000) - mRNA vaccine safety profile\n",
      "  3. B1 (score=0.0000) - COVID-19 mRNA vaccines\n",
      "\n",
      "üìä Query [Q3]: Entity embeddings and graph-based retrieval methods in knowledge graphs\n",
      "  1. B3 (score=0.0000) - SARS-CoV-2 variants\n",
      "  2. B2 (score=0.0000) - mRNA vaccine safety profile\n",
      "  3. B1 (score=0.0000) - COVID-19 mRNA vaccines\n",
      "\n",
      "üìä Query [Q4]: Do apples and Mediterranean diet reduce cardiovascular risk?\n",
      "  1. X1 (score=1.0000) - Cardiovascular risk and diet\n",
      "  2. N2 (score=1.0000) - Mediterranean diet\n",
      "  3. F2 (score=0.5958) - US economy outlook\n",
      "\n",
      "üìä Query [Q5]: Are AI-related revenues influencing NASDAQ and S&P 500?\n",
      "  1. X3 (score=1.0000) - AI revenues and S&P 500\n",
      "  2. F3 (score=1.0000) - NASDAQ and tech stocks\n",
      "  3. F5 (score=0.7566) - Dow Jones and dividends\n"
     ]
    }
   ],
   "source": [
    "from src.retrievers.graph_faiss import GraphRetriever\n",
    "\n",
    "graph_r = GraphRetriever(\n",
    "    graph_model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "    device=None,                  # \"cuda:0\" se houver GPU\n",
    "    ner_backend=\"spacy\",\n",
    "    ner_model=\"en_core_web_trf\",  # backbone √∫nico\n",
    "    ner_use_noun_chunks=True,\n",
    "    ner_batch_size=64,\n",
    "    ner_n_process=1,\n",
    "    ner_allowed_labels=None,      # manter amplo para o lab\n",
    "    min_df=1,                     # entidades precisam aparecer em >=2 docs\n",
    "    use_faiss=True,\n",
    "    artifact_dir=None,\n",
    "    index_name=\"graph.index\",\n",
    "    entity_artifact_dir=None,\n",
    "    entity_force_rebuild=False,\n",
    ")\n",
    "\n",
    "print(\"üîß Construindo √≠ndice de grafo...\")\n",
    "print(f\"   Modelo: {graph_r.vec.encoder.model_name}\")\n",
    "print(f\"   Dimens√£o: {graph_r.vec.dim}d\")\n",
    "graph_r.build_index(docs)\n",
    "\n",
    "print(\"\\nüîç Executando retrieval (top-3 por query)...\")\n",
    "graph_results = graph_r.retrieve(queries, k=3)\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nüìä Query [{q.query_id}]: {q.text}\")\n",
    "    pairs = graph_results.get(q.query_id, [])\n",
    "    for rank, (doc_id, score) in enumerate(pairs, 1):\n",
    "        title = next(d.title for d in docs if d.doc_id == doc_id)\n",
    "        print(f\"  {rank}. {doc_id} (score={score:.4f}) - {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5005b2fe",
   "metadata": {},
   "source": [
    "### üìà An√°lise dos Resultados Graph\n",
    "\n",
    "**Observe**:\n",
    "- Queries com **entidades nomeadas fortes** (ex: \"mRNA\", \"COVID\", \"entity embeddings\") devem ranquear bem documentos relacionados\n",
    "- O retriever de grafo √© especialmente forte quando:\n",
    "  - Documento e query compartilham **entidades raras** (alto IDF)\n",
    "  - Entidades t√™m **alta similaridade sem√¢ntica** nos embeddings\n",
    "- Pode capturar rela√ß√µes que TF-IDF perde (par√°frases de entidades) e que Dense n√£o enfatiza (import√¢ncia de termos espec√≠ficos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289a978",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä Compara√ß√£o Lado a Lado dos Tr√™s Retrievers\n",
    "\n",
    "Vamos consolidar os resultados dos tr√™s m√©todos para facilitar a an√°lise comparativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e280f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Compara√ß√£o dos Retrievers (Top-3 por Query):\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query Q1: Are mRNA vaccines effective against COVID-19?\n",
      "================================================================================\n",
      "Retriever  Rank Doc  Score                       Title\n",
      "   TF-IDF     1  B1 0.9198      COVID-19 mRNA vaccines\n",
      "   TF-IDF     2  B2 0.7802 mRNA vaccine safety profile\n",
      "   TF-IDF     3  B5 0.5067          Long COVID studies\n",
      "    Dense     1  B1 0.7346      COVID-19 mRNA vaccines\n",
      "    Dense     2  B2 0.4246 mRNA vaccine safety profile\n",
      "    Dense     3  X2 0.3059     COVID-19 and US economy\n",
      "    Graph     1  B3 0.0000         SARS-CoV-2 variants\n",
      "    Graph     2  B2 0.0000 mRNA vaccine safety profile\n",
      "    Graph     3  B1 0.0000      COVID-19 mRNA vaccines\n",
      "\n",
      "================================================================================\n",
      "Query Q2: How do interest rates impact equity volatility and valuations?\n",
      "================================================================================\n",
      "Retriever  Rank Doc  Score                                Title\n",
      "   TF-IDF     1  F1 0.8616 Interest rates and equity volatility\n",
      "   TF-IDF     2  F2 0.4282                   US economy outlook\n",
      "   TF-IDF     3  F5 0.2362              Dow Jones and dividends\n",
      "    Dense     1  F1 0.6877 Interest rates and equity volatility\n",
      "    Dense     2  F2 0.2547                   US economy outlook\n",
      "    Dense     3  X3 0.2017              AI revenues and S&P 500\n",
      "    Graph     1  B3 0.0000                  SARS-CoV-2 variants\n",
      "    Graph     2  B2 0.0000          mRNA vaccine safety profile\n",
      "    Graph     3  B1 0.0000               COVID-19 mRNA vaccines\n",
      "\n",
      "================================================================================\n",
      "Query Q3: Entity embeddings and graph-based retrieval methods in knowledge graphs\n",
      "================================================================================\n",
      "Retriever  Rank Doc  Score                                  Title\n",
      "   TF-IDF     1  M2 0.7676                  Graph neural networks\n",
      "   TF-IDF     2  M3 0.7580 Hybrid retrieval (dense+lexical+graph)\n",
      "   TF-IDF     3  M1 0.5818        Entity embeddings for retrieval\n",
      "    Dense     1  M1 0.5521        Entity embeddings for retrieval\n",
      "    Dense     2  M2 0.5244                  Graph neural networks\n",
      "    Dense     3  X4 0.4226      Clinical trials and graph methods\n",
      "    Graph     1  B3 0.0000                    SARS-CoV-2 variants\n",
      "    Graph     2  B2 0.0000            mRNA vaccine safety profile\n",
      "    Graph     3  B1 0.0000                 COVID-19 mRNA vaccines\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_results(results, name):\n",
    "    \"\"\"Formata resultados em DataFrame para visualiza√ß√£o\"\"\"\n",
    "    rows = []\n",
    "    for q in queries:\n",
    "        pairs = results.get(q.query_id, [])[:3]\n",
    "        for rank, (doc_id, score) in enumerate(pairs, 1):\n",
    "            doc = next(d for d in docs if d.doc_id == doc_id)\n",
    "            rows.append({\n",
    "                'Query': q.query_id,\n",
    "                'Retriever': name,\n",
    "                'Rank': rank,\n",
    "                'Doc': doc_id,\n",
    "                'Score': f\"{score:.4f}\",\n",
    "                'Title': doc.title[:40]\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Concatena resultados\n",
    "df_tfidf = format_results(tfidf_results, \"TF-IDF\")\n",
    "df_dense = format_results(dense_results, \"Dense\")\n",
    "df_graph = format_results(graph_results, \"Graph\")\n",
    "\n",
    "df_all = pd.concat([df_tfidf, df_dense, df_graph], ignore_index=True)\n",
    "\n",
    "print(\"üìä Compara√ß√£o dos Retrievers (Top-3 por Query):\\n\")\n",
    "for qid in [\"Q1\", \"Q2\", \"Q3\"]:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query {qid}: {next(q.text for q in queries if q.query_id == qid)}\")\n",
    "    print('='*80)\n",
    "    subset = df_all[df_all['Query'] == qid]\n",
    "    print(subset[['Retriever', 'Rank', 'Doc', 'Score', 'Title']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4a8e4",
   "metadata": {},
   "source": [
    "### üîç An√°lise Comparativa\n",
    "\n",
    "| Retriever | For√ßa | Fraqueza |\n",
    "|-----------|-------|----------|\n",
    "| **TF-IDF** | ‚úì Match exato de termos<br>‚úì R√°pido e interpret√°vel | ‚úó N√£o captura sin√¥nimos<br>‚úó Sens√≠vel a vocabul√°rio |\n",
    "| **Dense** | ‚úì Similaridade sem√¢ntica<br>‚úì Generaliza√ß√£o | ‚úó Pode perder signal lexical espec√≠fico<br>‚úó Menos interpret√°vel |\n",
    "| **Graph** | ‚úì Captura entidades importantes<br>‚úì Pondera√ß√£o por IDF | ‚úó Depende da qualidade do NER<br>‚úó Mais lento (extra√ß√£o + embedding) |\n",
    "\n",
    "**Conclus√£o**: Cada retriever captura um **sinal complementar**. O retriever **h√≠brido** combina os tr√™s para obter o melhor de todos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303901d",
   "metadata": {},
   "source": [
    "---\n",
    "# üî¨ Explora√ß√£o Adicional: Dimens√µes e Normaliza√ß√£o\n",
    "\n",
    "Vamos verificar as dimens√µes e normas L2 dos vetores gerados por cada retriever para confirmar que est√£o corretamente normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb123af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Dimens√µes e Normaliza√ß√£o dos Vetores\n",
      "\n",
      "2025-10-30 00:44:53 | INFO     | tfidf.vectorizer | [logging.py:199] | ‚è±Ô∏è  Fit TF-IDF - iniciando...\n",
      "2025-10-30 00:44:53 | INFO     | tfidf.vectorizer | [logging.py:220] | ‚úì Fit TF-IDF - conclu√≠do em \u001b[32m2.3ms\u001b[0m\n",
      "2025-10-30 00:44:53 | INFO     | tfidf.vectorizer | [tfidf_vectorizer.py:19] | ‚úì TF-IDF fitted: vocab_size=171\n",
      "TF-IDF:\n",
      "   Dim:  171d | L2 norm: 1.000000 | Sparsity: 97.1%\n",
      "\n",
      "Dense (MiniLM):\n",
      "   Dim:  384d | L2 norm: 1.000000 | Sparsity: 0.0%\n",
      "2025-10-30 00:44:56 | INFO     | graph.vectorizer | [logging.py:199] | ‚è±Ô∏è  Fit Graph (NER + IDF) - iniciando...\n",
      "2025-10-30 00:44:57 | INFO     | graph.vectorizer | [logging.py:220] | ‚úì Fit Graph (NER + IDF) - conclu√≠do em \u001b[32m1.28s\u001b[0m\n",
      "2025-10-30 00:44:57 | INFO     | graph.vectorizer | [graph_vectorizer.py:49] | ‚úì Graph fitted: dim=1024, ents=5\n",
      "Entidades query: []\n",
      "No vocabul√°rio (IDF): []\n",
      "||v_g||: 0.0\n",
      "\n",
      "Graph (BGE-Large):\n",
      "   Dim: 1024d | L2 norm: 0.000000 | Sparsity: 100.0%\n",
      "\n",
      "‚úì Todos os vetores est√£o normalizados (L2 norm ‚âà 1.0)\n",
      "‚úì TF-IDF √© esparso; Dense e Graph s√£o densos\n"
     ]
    }
   ],
   "source": [
    "# Verifica dimens√µes e normaliza√ß√£o\n",
    "\n",
    "print(\"üìê Dimens√µes e Normaliza√ß√£o dos Vetores\\n\")\n",
    "\n",
    "# TF-IDF\n",
    "from src.vectorizers.tfidf_vectorizer import TFIDFVectorizer\n",
    "tf_vec = TFIDFVectorizer(dim=1000, min_df=1, backend=\"sklearn\")\n",
    "tf_vec.fit_corpus([(d.title or \"\") + \" \" + (d.text or \"\") for d in docs])\n",
    "v_tf = tf_vec.encode_text(queries[0].text)\n",
    "print(f\"TF-IDF:\")\n",
    "print(f\"   Dim: {v_tf.shape[0]:>4}d | L2 norm: {np.linalg.norm(v_tf):.6f} | Sparsity: {np.sum(v_tf == 0) / len(v_tf) * 100:.1f}%\")\n",
    "\n",
    "# Dense (MiniLM)\n",
    "from src.vectorizers.dense_vectorizer import DenseVectorizer\n",
    "dv = DenseVectorizer(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", device=None)\n",
    "v_d = dv.encode_query(queries[0].text)\n",
    "print(f\"\\nDense (MiniLM):\")\n",
    "print(f\"   Dim: {v_d.shape[0]:>4}d | L2 norm: {np.linalg.norm(v_d):.6f} | Sparsity: {np.sum(v_d == 0) / len(v_d) * 100:.1f}%\")\n",
    "\n",
    "# Graph\n",
    "from src.vectorizers.graph_vectorizer import GraphVectorizer\n",
    "gv = GraphVectorizer(graph_model_name=\"BAAI/bge-large-en-v1.5\", device=None,\n",
    "                     ner_backend=\"spacy\", ner_model=\"en_core_web_trf\",\n",
    "                     ner_use_noun_chunks=True, min_df=1)\n",
    "gv.fit_corpus([(d.title or \"\") + \" \" + (d.text or \"\") for d in docs])\n",
    "\n",
    "qtxt = queries[0].text\n",
    "ents_q = gv.encoder._extract_entities_batch([qtxt])[0]\n",
    "ents_in_vocab = [e for e in ents_q if e in gv.encoder.ent2idf]\n",
    "print(\"Entidades query:\", ents_q)\n",
    "print(\"No vocabul√°rio (IDF):\", ents_in_vocab)\n",
    "v_g = gv.encode_text(qtxt)\n",
    "print(\"||v_g||:\", float(np.linalg.norm(v_g)))\n",
    "\n",
    "print(f\"\\nGraph (BGE-Large):\")\n",
    "print(f\"   Dim: {v_g.shape[0]:>4}d | L2 norm: {np.linalg.norm(v_g):.6f} | Sparsity: {np.sum(v_g == 0) / len(v_g) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úì Todos os vetores est√£o normalizados (L2 norm ‚âà 1.0)\")\n",
    "print(\"‚úì TF-IDF √© esparso; Dense e Graph s√£o densos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4dfb9",
   "metadata": {},
   "source": [
    "### üìä Interpreta√ß√£o das Dimens√µes\n",
    "\n",
    "**TF-IDF** (1000d):\n",
    "- Dimens√£o = tamanho do vocabul√°rio (limitado por `max_features`)\n",
    "- **Altamente esparso**: maioria das dimens√µes √© zero (termos n√£o presentes)\n",
    "- Sparsity t√≠pica: 95-99%\n",
    "\n",
    "**Dense MiniLM** (384d):\n",
    "- Dimens√£o fixa definida pelo modelo\n",
    "- **Totalmente denso**: todas as dimens√µes t√™m valores n√£o-zero\n",
    "- Menor que BGE, mas ainda captura sem√¢ntica eficazmente\n",
    "\n",
    "**Graph BGE-Large** (1024d):\n",
    "- Dimens√£o = dimens√£o do encoder de entidades\n",
    "- **Denso**: composi√ß√£o ponderada de embeddings de entidades\n",
    "- Maior dimens√£o ‚Üí maior capacidade representacional\n",
    "\n",
    "**Normaliza√ß√£o L2**: Todos os vetores t√™m norma ‚âà 1.0, permitindo compara√ß√£o direta por inner-product (equivalente a cosseno)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
