# Datasets

Este mÃ³dulo fornece funcionalidades para carregar e manipular datasets de recuperaÃ§Ã£o de informaÃ§Ã£o no formato BEIR.

## ðŸ“š Sobre os Datasets

Este projeto utiliza datasets do **BEIR (Benchmarking IR)**, um benchmark heterogÃªneo para avaliaÃ§Ã£o de sistemas de recuperaÃ§Ã£o de informaÃ§Ã£o. Os datasets sÃ£o fornecidos no formato padronizado que inclui corpus de documentos, queries (consultas) e qrels (relevance judgments).

### Datasets Suportados

#### 1. **SciFact**
- **DescriÃ§Ã£o**: Dataset de verificaÃ§Ã£o de declaraÃ§Ãµes cientÃ­ficas baseado em artigos acadÃªmicos
- **DomÃ­nio**: CiÃªncia biomÃ©dica
- **Tamanho**: 
  - ~5.000 documentos (abstracts de artigos cientÃ­ficos)
  - ~300 queries (claims cientÃ­ficas para verificaÃ§Ã£o)
- **ComposiÃ§Ã£o**:
  - **Corpus**: Abstracts de artigos cientÃ­ficos com tÃ­tulo e texto
  - **Queries**: DeclaraÃ§Ãµes cientÃ­ficas que precisam ser verificadas
  - **Qrels**: Julgamentos de relevÃ¢ncia indicando quais documentos suportam/refutam cada claim
- **Splits disponÃ­veis**: train, dev, test
- **Fonte Original**: AllenAI (https://scifact.s3-us-west-2.amazonaws.com)
- **VersÃ£o BEIR**: Formato padronizado do benchmark BEIR
- **Caso de Uso**: Fact-checking cientÃ­fico, verificaÃ§Ã£o de claims biomÃ©dicas

#### 2. **FIQA**
- **DescriÃ§Ã£o**: Financial Opinion Mining and Question Answering
- **DomÃ­nio**: FinanÃ§as (posts de fÃ³runs financeiros e sites de Q&A)
- **Tamanho**:
  - ~57.000 documentos (posts e respostas de fÃ³runs financeiros)
  - ~6.600 queries (perguntas financeiras)
- **ComposiÃ§Ã£o**:
  - **Corpus**: Posts de comunidades financeiras (Stack Exchange, Reddit, etc.)
  - **Queries**: Perguntas sobre investimentos, finanÃ§as pessoais, mercados
  - **Qrels**: Julgamentos de relevÃ¢ncia baseados em upvotes e aceitaÃ§Ã£o de respostas
- **Splits disponÃ­veis**: train, dev, test
- **Caso de Uso**: Question answering em domÃ­nio financeiro, busca de opiniÃµes especializadas

#### 3. **NFCorpus**
- **DescriÃ§Ã£o**: Nutrition Facts Corpus - Linking PubMed articles to NutritionFacts.org articles
- **DomÃ­nio**: NutriÃ§Ã£o e medicina
- **Tamanho**:
  - ~3.600 documentos (artigos mÃ©dicos do PubMed)
  - ~323 queries (tÃ­tulos de artigos do NutritionFacts.org)
- **ComposiÃ§Ã£o**:
  - **Corpus**: Abstracts de artigos mÃ©dicos sobre nutriÃ§Ã£o
  - **Queries**: Consultas baseadas em artigos de divulgaÃ§Ã£o cientÃ­fica
  - **Qrels**: Links entre artigos cientÃ­ficos e divulgaÃ§Ã£o
- **Splits disponÃ­veis**: train, dev, test
- **Caso de Uso**: RecuperaÃ§Ã£o de evidÃªncias cientÃ­ficas para artigos de divulgaÃ§Ã£o, cross-domain retrieval

### Formato BEIR Padronizado

Todos os datasets seguem o formato BEIR com trÃªs componentes principais:

1. **corpus.{parquet|jsonl}**: Documentos indexÃ¡veis
   - `doc_id`: Identificador Ãºnico do documento
   - `title`: TÃ­tulo do documento (opcional)
   - `text`: ConteÃºdo textual principal
   - `metadata`: Metadados adicionais (opcional)

2. **queries.{parquet|jsonl}**: Consultas de busca
   - `query_id`: Identificador Ãºnico da query
   - `query`: Texto da consulta

3. **qrels.{parquet|jsonl}**: Julgamentos de relevÃ¢ncia (ground truth)
   - `query_id`: ID da query
   - `doc_id`: ID do documento
   - `score`: Grau de relevÃ¢ncia (tipicamente 0 ou 1, mas pode variar)
   - `split`: PartiÃ§Ã£o do dataset (train/dev/test)

## ðŸš€ PreparaÃ§Ã£o dos Dados

### PrÃ©-requisitos

Antes de usar os datasets neste formato, vocÃª precisa executar o script de download:

```bash
# Instalar dependÃªncias necessÃ¡rias
pip install pandas pyarrow requests tqdm

# Para SciFact via Hugging Face (opcional):
pip install datasets
```

### Download e Processamento

Execute o script `download_datasets.py` na raiz do projeto:

```bash
# Baixar todos os datasets (SciFact, FIQA, NFCorpus)
python download_datasets.py \
  --datasets scifact,fiqa,nfcorpus \
  --root ./data \
  --format parquet

# Baixar apenas SciFact
python download_datasets.py \
  --datasets scifact \
  --root ./data \
  --format parquet

# Usar Hugging Face como fonte para SciFact
python download_datasets.py \
  --datasets scifact \
  --root ./data \
  --format parquet \
  --scifact-source hf
```

### Estrutura de DiretÃ³rios Criada

ApÃ³s executar o script de download, a seguinte estrutura serÃ¡ criada:

```
data/
â”œâ”€â”€ scifact/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ original/         # Formato original do AllenAI
â”‚   â”‚   â”‚   â””â”€â”€ data.tar.gz
â”‚   â”‚   â””â”€â”€ beir/             # Formato BEIR
â”‚   â”‚       â”œâ”€â”€ scifact.zip
â”‚   â”‚       â””â”€â”€ extracted/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ original/         # Normalizado em parquet
â”‚       â”‚   â”œâ”€â”€ corpus.parquet
â”‚       â”‚   â”œâ”€â”€ claims_train.parquet
â”‚       â”‚   â”œâ”€â”€ claims_dev.parquet
â”‚       â”‚   â””â”€â”€ claims_test.parquet
â”‚       â””â”€â”€ beir/             # Normalizado em parquet
â”‚           â”œâ”€â”€ corpus.parquet
â”‚           â”œâ”€â”€ queries.parquet
â”‚           â””â”€â”€ qrels.parquet
â”œâ”€â”€ fiqa/
â”‚   â”œâ”€â”€ raw/beir/
â”‚   â”‚   â”œâ”€â”€ fiqa.zip
â”‚   â”‚   â””â”€â”€ extracted/
â”‚   â””â”€â”€ processed/beir/
â”‚       â”œâ”€â”€ corpus.parquet
â”‚       â”œâ”€â”€ queries.parquet
â”‚       â””â”€â”€ qrels.parquet
â””â”€â”€ nfcorpus/
    â”œâ”€â”€ raw/beir/
    â”‚   â”œâ”€â”€ nfcorpus.zip
    â”‚   â””â”€â”€ extracted/
    â””â”€â”€ processed/beir/
        â”œâ”€â”€ corpus.parquet
        â”œâ”€â”€ queries.parquet
        â””â”€â”€ qrels.parquet
```

## ðŸ”§ Uso do MÃ³dulo

### Funcionalidades do CÃ³digo

Este mÃ³dulo (`src/datasets/`) fornece duas funcionalidades principais:

#### 1. **Schema de Dados** (`schema.py`)

Define estruturas de dados tipadas para documentos e queries:

```python
from src.datasets.schema import Document, Query

# Document: representa um documento do corpus
doc = Document(
    doc_id="12345",
    title="TÃ­tulo do documento",
    text="ConteÃºdo do documento...",
    metadata={"author": "JoÃ£o Silva"}
)

# Query: representa uma consulta
query = Query(
    query_id="q1",
    text="Como investir em aÃ§Ãµes?"
)
```

#### 2. **Carregamento de Dados** (`loader.py`)

FunÃ§Ãµes para carregar datasets BEIR processados:

##### `load_beir_dataset(root: Path)`

Carrega os trÃªs componentes de um dataset BEIR:

```python
from pathlib import Path
from src.datasets.loader import load_beir_dataset

# Carregar dataset SciFact
root = Path("data/scifact/processed/beir")
corpus, queries, qrels = load_beir_dataset(root)

# Retorna 3 DataFrames do pandas:
# - corpus: DataFrame com colunas [doc_id, title, text, metadata]
# - queries: DataFrame com colunas [query_id, query]
# - qrels: DataFrame com colunas [query_id, doc_id, score, split]
```

**CaracterÃ­sticas**:
- Suporta tanto **Parquet** (preferencial) quanto **JSONL** (fallback)
- Normaliza tipos de dados (IDs como strings)
- Adiciona coluna `split` padrÃ£o ("test") se ausente
- Adiciona coluna `score` padrÃ£o (1) se ausente
- Tratamento robusto de erros com fallback automÃ¡tico

##### `select_split(qrels: DataFrame, prefer=("test","dev","validation","train"))`

Seleciona automaticamente o split mais apropriado:

```python
from src.datasets.loader import select_split

# Selecionar split preferencial
split_name = select_split(qrels)  # Retorna "test" se disponÃ­vel
split_name = select_split(qrels, prefer=("dev", "test"))  # Prioriza "dev"

# Filtrar qrels pelo split selecionado
qrels_split = qrels[qrels["split"] == split_name]
```

##### `as_documents(corpus: DataFrame)` e `as_queries(queries: DataFrame)`

Converte DataFrames para listas de objetos tipados:

```python
from src.datasets.loader import as_documents, as_queries

# Converter para objetos Document
docs = as_documents(corpus)  # List[Document]

# Converter para objetos Query
qs = as_queries(queries)  # List[Query]

# Usar em cÃ³digo tipado
for doc in docs:
    print(f"{doc.doc_id}: {doc.title}")
```


## ðŸ“Š EstatÃ­sticas dos Datasets

| Dataset   | Documentos | Queries (test) | Avg Doc Length | Avg Query Length | DomÃ­nio |
|-----------|------------|----------------|----------------|------------------|---------|
| SciFact   | ~5K        | ~300           | ~200 tokens    | ~20 tokens       | CiÃªncia |
| FIQA      | ~57K       | ~6.6K          | ~130 tokens    | ~11 tokens       | FinanÃ§as|
| NFCorpus  | ~3.6K      | ~323           | ~250 tokens    | ~3 tokens        | NutriÃ§Ã£o|


## ðŸ“– ReferÃªncias

- **BEIR Benchmark**: Thakur, N., et al. (2021). "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models"
- **SciFact**: Wadden, D., et al. (2020). "Fact or Fiction: Verifying Scientific Claims"
- **FIQA**: Maia, M., et al. (2018). "WWW'18 Open Challenge: Financial Opinion Mining and Question Answering"
- **NFCorpus**: Boteva, V., et al. (2016). "A Full-Text Learning to Rank Dataset for Medical Information Retrieval"

