# ğŸ”¬ Hybrid Retrieval Framework

**Autor**: Thiago Pedroso de Jesus  
**InstituiÃ§Ã£o**: ResidÃªncia em IA - Bacharelado em InteligÃªncia Artificial - UFG

---

## ğŸ“– Sobre o Projeto

Este repositÃ³rio implementa um **framework modular e extensÃ­vel para experimentaÃ§Ã£o com sistemas de Retrieval-Augmented Generation (RAG)**, com foco especial em **busca hÃ­brida multi-modal**. O framework permite combinar diferentes estratÃ©gias de recuperaÃ§Ã£o de informaÃ§Ã£o (semÃ¢ntica, lexical, baseada em grafos de entidades) de forma flexÃ­vel e configurÃ¡vel.

### ğŸ¯ Objetivo

Fornecer uma estrutura robusta e flexÃ­vel para:

- âœ… **ExperimentaÃ§Ã£o rÃ¡pida** com diferentes tÃ©cnicas de retrieval
- âœ… **Busca hÃ­brida multi-modal** (semantic + lexical + graph)
- âœ… **AvaliaÃ§Ã£o rigorosa** usando mÃ©tricas padrÃ£o de IR (nDCG, MRR, MAP, Recall, Precision)
- âœ… **ComparaÃ§Ã£o sistemÃ¡tica** entre diferentes abordagens
- âœ… **Reprodutibilidade** via configuraÃ§Ãµes YAML declarativas
- âœ… **Extensibilidade** atravÃ©s de arquitetura baseada em interfaces (ABCs)

### ğŸŒŸ CaracterÃ­sticas Principais

- **Modular**: Componentes intercambiÃ¡veis (vectorizers, indexes, fusers, rerankers)
- **Multi-modal**: Suporte nativo para busca tri-modal (semantic + TF-IDF + entities)
- **ConfigurÃ¡vel**: Experimentos definidos via YAML (sem cÃ³digo)
- **ExtensÃ­vel**: FÃ¡cil adicionar novos retrievers, vectorizers ou estratÃ©gias de fusÃ£o
- **Eficiente**: Usa FAISS para busca vetorial rÃ¡pida, com suporte a GPU
- **ReproduzÃ­vel**: Cache de Ã­ndices, entidades e resultados de LLM judges
- **BenchmarkÃ¡vel**: Suporte nativo para datasets BEIR (SciFact, FIQA, NFCorpus, SQuAD)

---

## ğŸ—ï¸ Arquitetura

O framework segue uma **arquitetura modular baseada em interfaces (ABCs)**, onde cada componente tem uma responsabilidade Ãºnica:

``` mermaid
flowchart TD

    A["EXPERIMENT RUNNER<br>(Orquestra pipeline completo)"]

    A --> B["RETRIEVERS<br>(Coordenadores)"]
    A --> C["DATASETS<br>(BEIR)"]

    B --> D["VECTORIZER<br>(Textoâ†’Vec)"]
    B --> E["INDEX<br>(Busca)"]
    B --> F["FUSION<br>(Combina)"]

    D --> G["ENCODERS<br>(Building)"]
    F --> H["RERANKER<br>(Refina)"]
```

### ğŸ“¦ Componentes

1. **Vectorizers** (`src/vectorizers/`): Convertem texto em vetores multi-modais
   - Dense (semantic embeddings)
   - TF-IDF (lexical)
   - Tri-Modal (semantic + TF-IDF + entities)
   - Bi-Modal (combinaÃ§Ãµes de 2 modalidades)
   - Graph (apenas entidades)

2. **Indexes** (`src/indexes/`): Estruturas de busca vetorial eficiente
   - FAISS (busca exata e aproximada)
   - Suporte a GPU
   - PersistÃªncia (cache)

3. **Retrievers** (`src/retrievers/`): Orquestram pipeline completo
   - Dense (apenas semantic)
   - BM25 (baseline lexical)
   - Hybrid (tri-modal com reranking)
   - DAT (Dynamic Alpha Tuning com LLM judge)
   - Baseline Hybrid (alpha fixo)

4. **Fusion** (`src/fusion/`): Combinam resultados de mÃºltiplas modalidades
   - Weighted Cosine (soma ponderada)
   - Reciprocal Rank Fusion (RRF)
   - DAT Linear (alpha adaptativo)
   - Weight Policies (static, heuristic, LLM-based)

5. **Evaluation** (`src/eval/`): MÃ©tricas de avaliaÃ§Ã£o
   - nDCG@k (Normalized Discounted Cumulative Gain)
   - MRR (Mean Reciprocal Rank)
   - MAP (Mean Average Precision)
   - Recall@k e Precision@k

6. **Datasets** (`src/datasets/`): Loaders para datasets BEIR
   - SciFact (verificaÃ§Ã£o cientÃ­fica)
   - FIQA (Q&A financeiro)
   - NFCorpus (nutriÃ§Ã£o/medicina)
   - SQuAD (question answering)

---

## ğŸš€ Quick Start

### 1. InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/hybrid-retrieval.git
cd hybrid-retrieval

# Setup automÃ¡tico (cria venv e instala dependÃªncias)
./setup_venv.sh

# Ou manual
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

### 2. Download dos Datasets

```bash
# Baixar datasets BEIR (SciFact, FIQA, NFCorpus)
python download_datasets.py \
  --datasets scifact,fiqa,nfcorpus \
  --root ./data \
  --format parquet

# Apenas SciFact (para testes rÃ¡pidos)
python download_datasets.py \
  --datasets scifact \
  --root ./data \
  --format parquet
```

### 3. Executar Primeiro Experimento

```bash
# Ativar ambiente
source .venv/bin/activate

# Executar experimento baseline (Dense retriever em SciFact)
python scripts/run_experiment.py \
  --config configs/individuals/dense_scifact.yaml

# Ver resultados
cat outputs/experiments/default/dense_scifact.csv
```

### 4. Experimento Tri-Modal

```bash
# Retriever tri-modal com reranking adaptativo
python scripts/run_experiment.py \
  --config configs/trimodal/tri_modal_scifact.yaml

# Comparar com baseline
python scripts/run_experiment.py \
  --config configs/individuals/dense_scifact.yaml

# Resultados em: outputs/experiments/
```

---

## ğŸ“ Estrutura do Projeto

```
hybrid-retrieval/
â”œâ”€â”€ configs/                    # ConfiguraÃ§Ãµes YAML de experimentos
â”‚   â”œâ”€â”€ individuals/           # Retrievers individuais (dense, tfidf, bm25, graph)
â”‚   â”œâ”€â”€ bimodal/               # CombinaÃ§Ãµes bimodais
â”‚   â”œâ”€â”€ trimodal/              # Tri-modal (semantic+tfidf+graph)
â”‚   â”œâ”€â”€ dat_experiments/       # Experimentos DAT (Dynamic Alpha Tuning)
â”‚   â””â”€â”€ dat_hs/                # Experimentos em dataset HS (HotpotQA-based)
â”œâ”€â”€ data/                      # Datasets BEIR processados
â”‚   â”œâ”€â”€ scifact/
â”‚   â”œâ”€â”€ fiqa/
â”‚   â”œâ”€â”€ nfcorpus/
â”‚   â””â”€â”€ squad*/                # SQuAD e variaÃ§Ãµes
â”œâ”€â”€ scripts/                   # Scripts de execuÃ§Ã£o e anÃ¡lise
â”‚   â”œâ”€â”€ run_experiment.py      # Executor principal (via YAML)
â”‚   â”œâ”€â”€ run_individual_retrievers.py
â”‚   â”œâ”€â”€ run_bimodal_benchmark.py
â”‚   â”œâ”€â”€ evaluate.py            # AvaliaÃ§Ã£o de prediÃ§Ãµes
â”‚   â”œâ”€â”€ compare_hs_results.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                       # CÃ³digo-fonte do framework
â”‚   â”œâ”€â”€ config/                # Sistema de configuraÃ§Ã£o (Pydantic schemas)
â”‚   â”œâ”€â”€ core/                  # Interfaces (ABCs)
â”‚   â”œâ”€â”€ datasets/              # Loaders BEIR
â”‚   â”œâ”€â”€ encoders/              # Building blocks (semantic, tfidf, entities)
â”‚   â”œâ”€â”€ vectorizers/           # Combinadores de encoders
â”‚   â”œâ”€â”€ indexes/               # FAISS e outros Ã­ndices
â”‚   â”œâ”€â”€ retrievers/            # Retrievers completos
â”‚   â”œâ”€â”€ fusion/                # EstratÃ©gias de fusÃ£o e reranking
â”‚   â”œâ”€â”€ eval/                  # MÃ©tricas de avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ experiments/           # Experiment runner
â”‚   â””â”€â”€ utils/                 # Logging e utilitÃ¡rios
â”œâ”€â”€ tests/                     # Testes unitÃ¡rios e de integraÃ§Ã£o
â”œâ”€â”€ outputs/                   # Resultados de experimentos
â”‚   â”œâ”€â”€ experiments/           # CSVs e JSONs de mÃ©tricas
â”‚   â””â”€â”€ artifacts/             # Ãndices FAISS, caches de entidades
â”œâ”€â”€ requirements.txt           # DependÃªncias Python
â”œâ”€â”€ setup_venv.sh              # Setup automÃ¡tico
â””â”€â”€ README.md                  # Este arquivo
```

---

## ğŸ¯ Como Usar

### OpÃ§Ã£o 1: Via ConfiguraÃ§Ã£o YAML (Recomendado)

```yaml
# configs/my_experiment.yaml
experiment:
  name: "my_first_experiment"
  output_dir: "./outputs/experiments/my_first"

dataset:
  name: "scifact"
  root: "./data/scifact/processed/beir"

retrievers:
  - name: "dense_minilm"
    type: "dense"
    vectorizer:
      type: "dense"
      semantic:
        model: "sentence-transformers/all-MiniLM-L6-v2"
    index:
      type: "faiss"
      metric: "ip"

  - name: "trimodal_hybrid"
    type: "hybrid"
    vectorizer:
      type: "tri_modal"
      semantic:
        model: "sentence-transformers/all-MiniLM-L6-v2"
      tfidf:
        dim: 1000
      graph:
        model: "BAAI/bge-large-en-v1.5"
    fusion:
      strategy: "weighted_cosine"
      policy: "heuristic"
    reranker:
      type: "tri_modal"
      topk_first: 150

metrics: ["nDCG", "MRR", "MAP", "Recall", "Precision"]
ks: [1, 3, 5, 10]
output_formats: ["csv", "json"]
```

```bash
python scripts/run_experiment.py --config configs/my_experiment.yaml
```

### OpÃ§Ã£o 2: Via Python

```python
from pathlib import Path
from src.config.loader import load_config
from src.experiments.runner import ExperimentRunner

# Carregar configuraÃ§Ã£o
config = load_config("configs/my_experiment.yaml")

# Executar experimento
runner = ExperimentRunner(config)
results_df = runner.run()

# Analisar resultados
print(results_df[results_df["k"] == 10][["retriever", "nDCG", "MRR"]])
```

### OpÃ§Ã£o 3: Uso ProgramÃ¡tico (Para Desenvolvimento)

```python
from src.retrievers.hybrid_faiss import HybridRetriever
from src.vectorizers.tri_modal_vectorizer import TriModalVectorizer
from src.indexes.hybrid_index import HybridIndex
from src.datasets.loader import load_beir_dataset, as_documents, as_queries

# Carregar dataset
corpus, queries, qrels = load_beir_dataset(Path("data/scifact/processed/beir"))
docs = as_documents(corpus)
qs = as_queries(queries)

# Criar retriever
vectorizer = TriModalVectorizer(
    semantic_model_name="sentence-transformers/all-MiniLM-L6-v2",
    tfidf_dim=1000,
    graph_model_name="BAAI/bge-large-en-v1.5",
)
index = HybridIndex(vectorizer=vectorizer)
retriever = HybridRetriever(vectorizer, index, ...)

# Construir Ã­ndice
retriever.build_index(docs)

# Buscar
results = retriever.retrieve(qs, k=10)
# results: {"q1": [("doc1", 0.95), ...], ...}
```

---

## ğŸ§ª Experimentos DisponÃ­veis

### 1. Retrievers Individuais (`configs/individuals/`)

Teste cada modalidade separadamente:

```bash
# Dense (semantic apenas)
python scripts/run_experiment.py --config configs/individuals/dense_scifact.yaml

# TF-IDF (lexical apenas)
python scripts/run_experiment.py --config configs/individuals/tfidf_scifact.yaml

# BM25 (baseline lexical)
python scripts/run_experiment.py --config configs/individuals/bm25_scifact.yaml

# Graph (entidades apenas)
python scripts/run_experiment.py --config configs/individuals/graph_scifact.yaml
```

### 2. CombinaÃ§Ãµes Bimodais (`configs/bimodal/`)

```bash
# Semantic + TF-IDF
python scripts/run_experiment.py --config configs/bimodal/semantic_tfidf_scifact.yaml

# Semantic + Graph
python scripts/run_experiment.py --config configs/bimodal/semantic_graph_scifact.yaml

# TF-IDF + Graph
python scripts/run_experiment.py --config configs/bimodal/tfidf_graph_scifact.yaml
```

### 3. Tri-Modal (`configs/trimodal/`)

```bash
# Tri-modal com pesos adaptativos (heurÃ­sticos)
python scripts/run_experiment.py --config configs/trimodal/tri_modal_scifact.yaml

# Tri-modal com pesos estÃ¡ticos
python scripts/run_experiment.py --config configs/trimodal/tri_modal_static_scifact.yaml

# Tri-modal com RRF (Reciprocal Rank Fusion)
python scripts/run_experiment.py --config configs/trimodal/tri_modal_rrf_scifact.yaml
```

### 4. DAT (Dynamic Alpha Tuning) (`configs/dat_experiments/`)

Experimentos usando LLM judges para determinar pesos adaptativos:

```bash
# Baselines (alpha fixo)
python scripts/run_experiment.py --config configs/dat_experiments/01_baseline_alpha_0.0_bm25_only.yaml
python scripts/run_experiment.py --config configs/dat_experiments/03_baseline_alpha_0.6.yaml
python scripts/run_experiment.py --config configs/dat_experiments/04_baseline_alpha_1.0_dense_only.yaml

# DAT com OpenAI
python scripts/run_experiment.py --config configs/dat_experiments/05_dat_hybrid_gpt4o_mini.yaml
python scripts/run_experiment.py --config configs/dat_experiments/06_dat_hybrid_gpt4o.yaml

# DAT com Ollama (local)
python scripts/run_experiment.py --config configs/dat_experiments/09_dat_hybrid_llama31.yaml
python scripts/run_experiment.py --config configs/dat_experiments/10_dat_hybrid_llama_finetune.yaml
```

---

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Cache e Artefatos

O framework usa cache agressivo para acelerar experimentos:

```bash
# Estrutura de cache
outputs/
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ faiss_indexes/      # Ãndices FAISS construÃ­dos
â”‚   â”œâ”€â”€ entity_caches/      # Entidades extraÃ­das (NER)
â”‚   â””â”€â”€ llm_judge_cache/    # Respostas de LLM judges
```

Para forÃ§ar rebuild:

```yaml
# No YAML de configuraÃ§Ã£o
index:
  type: "faiss"
  force_rebuild: true  # ForÃ§a reconstruÃ§Ã£o do Ã­ndice

vectorizer:
  graph:
    entity_cache: "./cache/entities"
    force_rebuild: true  # ForÃ§a re-extraÃ§Ã£o de entidades
```

### OtimizaÃ§Ãµes para MÃ¡quinas com Pouca MemÃ³ria

```yaml
# Reduzir batch size de NER
vectorizer:
  graph:
    ner_batch_size: 4      # PadrÃ£o: 8
    ner_n_process: 1       # PadrÃ£o: 4

# Usar Ã­ndice FAISS comprimido
index:
  type: "faiss"
  factory: "IVF4096,Flat"  # Ao invÃ©s de FlatIP (exato)
  nprobe: 64
```

### GPU Acceleration

```yaml
# FAISS automaticamente detecta e usa GPU se disponÃ­vel
index:
  type: "faiss"
  use_gpu: true  # Tenta usar GPU (MPS no Mac M1, CUDA no NVIDIA)
```

---

## ğŸ“Š AvaliaÃ§Ã£o e MÃ©tricas

### MÃ©tricas DisponÃ­veis

- **nDCG@k**: Normalized Discounted Cumulative Gain (principal mÃ©trica)
- **MRR**: Mean Reciprocal Rank (ranking do primeiro relevante)
- **MAP**: Mean Average Precision (precisÃ£o mÃ©dia)
- **Recall@k**: FraÃ§Ã£o de documentos relevantes recuperados
- **Precision@k**: FraÃ§Ã£o de documentos recuperados que sÃ£o relevantes

### AnÃ¡lise de Resultados

```python
import pandas as pd

# Carregar resultados
df = pd.read_csv("outputs/experiments/my_experiment/results.csv")

# Comparar retrievers em nDCG@10
summary = df[df["k"] == 10].groupby("retriever")["nDCG"].mean()
print(summary.sort_values(ascending=False))

# Visualizar performance por k
import matplotlib.pyplot as plt

for retriever in df["retriever"].unique():
    subset = df[df["retriever"] == retriever]
    plt.plot(subset["k"], subset["nDCG"], label=retriever, marker='o')

plt.xlabel("k")
plt.ylabel("nDCG@k")
plt.legend()
plt.title("Performance por Retriever")
plt.show()
```

---

## ğŸ› ï¸ Extensibilidade

O framework foi projetado para ser facilmente extensÃ­vel. Para adicionar novos componentes:

### Adicionar Novo Vectorizer

1. Crie classe implementando `AbstractVectorizer` em `src/vectorizers/`
2. Registre na factory `src/vectorizers/factory.py`
3. Atualize schema em `src/config/schema.py`
4. Use via YAML

Exemplo: veja `src/vectorizers/README.md`

### Adicionar Novo Retriever

1. Crie classe implementando `AbstractRetriever` em `src/retrievers/`
2. Registre na factory `src/retrievers/factory.py`
3. Atualize schema
4. Use via YAML

Exemplo: veja `src/retrievers/README.md`

### Adicionar Nova EstratÃ©gia de FusÃ£o

1. Crie classe implementando `AbstractFusionStrategy` em `src/fusion/strategies.py`
2. Registre no dict `FUSION_STRATEGIES`
3. Use via YAML

Exemplo: veja `src/fusion/README.md`

### Adicionar Nova MÃ©trica

1. Crie classe implementando `AbstractMetric` em `src/eval/metrics.py`
2. Registre em `METRICS_REGISTRY`
3. Use via YAML em `metrics: ["MinhaMetrica"]`

---

## ğŸ“š Datasets Suportados

### SciFact
- **DomÃ­nio**: VerificaÃ§Ã£o cientÃ­fica (biomedicina)
- **Tamanho**: ~5K docs, ~300 queries
- **Uso**: Fact-checking de claims cientÃ­ficas

### FIQA
- **DomÃ­nio**: FinanÃ§as (Q&A de fÃ³runs)
- **Tamanho**: ~57K docs, ~6.6K queries
- **Uso**: Question answering financeiro

### NFCorpus
- **DomÃ­nio**: NutriÃ§Ã£o e medicina
- **Tamanho**: ~3.6K docs, ~323 queries
- **Uso**: Linking entre artigos cientÃ­ficos e divulgaÃ§Ã£o

### SQuAD (VariaÃ§Ãµes Customizadas)
- **squad_small**: Subset pequeno para testes rÃ¡pidos
- **squad_llm_judge**: Dataset com julgamentos de LLM para treinar judges

---

## ğŸ§© DependÃªncias Principais

- **sentence-transformers**: Embeddings semÃ¢nticos
- **transformers**: Modelos Hugging Face
- **faiss-cpu** (ou faiss-gpu): Busca vetorial rÃ¡pida
- **scikit-learn**: TF-IDF e mÃ©tricas
- **scispacy**: NER para domÃ­nio cientÃ­fico
- **rank-bm25**: ImplementaÃ§Ã£o BM25
- **pydantic**: ValidaÃ§Ã£o de configuraÃ§Ãµes
- **pandas**, **numpy**, **pyarrow**: ManipulaÃ§Ã£o de dados

Veja `requirements.txt` para lista completa.

---

## ğŸ”¬ AplicaÃ§Ãµes

Este framework Ã© Ãºtil para:

- âœ… **Pesquisa em RAG**: Testar diferentes estratÃ©gias de retrieval
- âœ… **Benchmarking**: Comparar mÃ©todos em datasets padronizados
- âœ… **ProduÃ§Ã£o**: Base para sistemas de busca hÃ­brida
- âœ… **EducaÃ§Ã£o**: Aprender sobre IR e RAG na prÃ¡tica
- âœ… **Desenvolvimento**: Prototipar novas tÃ©cnicas de retrieval

---

## ğŸ“– DocumentaÃ§Ã£o Adicional

Para documentaÃ§Ã£o detalhada de cada mÃ³dulo:

- `src/README.md` - VisÃ£o geral da arquitetura
- `src/vectorizers/README.md` - Como criar vectorizers
- `src/retrievers/README.md` - Como criar retrievers
- `src/fusion/README.md` - EstratÃ©gias de fusÃ£o e reranking
- `src/eval/README.md` - MÃ©tricas de avaliaÃ§Ã£o
- `src/datasets/README.md` - Datasets BEIR
- `configs/README.md` - Estrutura de configuraÃ§Ãµes

---

## ğŸ§ª Testes

```bash
# Executar todos os testes
pytest

# Testes de integraÃ§Ã£o
pytest tests/test_integration_modular.py

# Testes de mÃ©tricas
pytest tests/test_metrics_*.py

# Testes end-to-end
pytest tests/test_cli_end2end_scifact.py
```

---

## ğŸ“š ReferÃªncias

### Papers

1. **BEIR**: Thakur, N., et al. (2021). "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models"
2. **DAT**: "Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models" (2024)
3. **RRF**: Cormack, G. V., et al. (2009). "Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods"
4. **BM25**: Robertson, S., Zaragoza, H. (2009). "The Probabilistic Relevance Framework: BM25 and Beyond"

### Datasets

- **SciFact**: Wadden, D., et al. (2020). "Fact or Fiction: Verifying Scientific Claims"
- **FIQA**: Maia, M., et al. (2018). "WWW'18 Open Challenge: Financial Opinion Mining and Question Answering"
- **NFCorpus**: Boteva, V., et al. (2016). "A Full-Text Learning to Rank Dataset for Medical Information Retrieval"

### Bibliotecas

- **FAISS**: [https://github.com/facebookresearch/faiss](https://github.com/facebookresearch/faiss)
- **Sentence-Transformers**: [https://www.sbert.net/](https://www.sbert.net/)
- **spaCy**: [https://spacy.io/](https://spacy.io/)
- **scikit-learn**: [https://scikit-learn.org/](https://scikit-learn.org/)
