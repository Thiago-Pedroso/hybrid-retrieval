# ğŸ”¬ Hybrid Retrieval: Tri-Modal Fusion

Autor: Thiago Pedroso de Jesus

RepositÃ³rio destinado ao desenvolvimento do projeto final da ResidÃªncia em IA no Bacharelado em InteligÃªncia 
Artificial da UFG.

**ReplicaÃ§Ã£o do paper**: ["Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models"](https://arxiv.org/pdf/2506.00049)

O objetivo Ã© fazer um sistema de **retrieval hÃ­brido tri-modal** que combina embeddings semÃ¢nticos, representaÃ§Ãµes lexicais (TF-IDF) e embeddings de entidades para recuperaÃ§Ã£o de documentos.

## ğŸ¯ **Objetivo do Paper**

O paper ["Rethinking Hybrid Retrieval"](https://arxiv.org/pdf/2506.00049) demonstra que:

1. **Embeddings pequenos** (MiniLM) podem superar modelos maiores (BGE-Large) em retrieval hÃ­brido
2. **LLM re-ranking** na segunda fase Ã© mais importante que embeddings grandes
3. **Tri-modal fusion** (semantic + lexical + graph) Ã© superior a abordagens unimodais
4. **Pesos adaptativos** sÃ£o cruciais para diferentes tipos de queries

---

## ğŸ—ï¸ **Arquitetura do Sistema**

### **Tri-Modal Vectorizer**

O sistema combina trÃªs modalidades:

1. **Semantic (s)**: Embeddings de sentenÃ§as
   - MiniLM-L6-v2: 384d
   - BGE-Large: 1024d

2. **Lexical (t)**: TF-IDF sparse
   - DimensÃ£o: 1000d
   - Backend: scikit-learn

3. **Graph (g)**: Embeddings de entidades
   - ExtraÃ§Ã£o: spaCy/scispaCy NER
   - Embedding: BGE-Large (1024d)
   - AgregaÃ§Ã£o: TF-IDF weighted

### **Pipeline de Retrieval**

```
Query â†’ [s; t; g] â†’ FAISS Search â†’ Re-ranking â†’ Top-k Results
```

1. **Encoding**: Query convertida para vetor tri-modal `[semantic; tfidf; entities]`
2. **Search**: Busca por similaridade no Ã­ndice FAISS
3. **Re-ranking**: CombinaÃ§Ã£o de cosenos com pesos adaptativos
4. **Output**: Top-k documentos ranqueados

---

## ğŸ“ˆ **MÃ©tricas Utilizadas**

### **MÃ©tricas de Retrieval**

- **nDCG@k**: Normalized Discounted Cumulative Gain
- **MRR**: Mean Reciprocal Rank  
- **MAP**: Mean Average Precision
- **Recall@k**: Taxa de recuperaÃ§Ã£o
- **Precision@k**: PrecisÃ£o dos top-k

### **MÃ©tricas de Performance**

- **Tempo de IndexaÃ§Ã£o**: Build do Ã­ndice FAISS
- **Tempo de Retrieval**: Busca + re-ranking
- **Uso de MemÃ³ria**: RAM peak durante processamento

---

## ğŸ—‚ï¸ **Datasets Suportados**

### **BEIR Benchmark**

- **SciFact**: Scientific Claims
- **FIQA**: Financial Q&A dataset
- **NFCorpus**: Medical domain corpus

### **Formato de Dados**

```
data/
â”œâ”€â”€ scifact/
â”‚   â”œâ”€â”€ corpus.jsonl
â”‚   â”œâ”€â”€ queries.jsonl
â”‚   â””â”€â”€ qrels/
â”‚       â”œâ”€â”€ test.jsonl
â”‚       â””â”€â”€ dev.jsonl
```

---

## ğŸ“ **Estrutura do Projeto**

```
hybrid-retrieval/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datasets/          # Loaders de datasets BEIR
â”‚   â”œâ”€â”€ retrievers/        # ImplementaÃ§Ãµes de retrieval
â”‚   â”œâ”€â”€ tri_modal/         # Vectorizer tri-modal
â”‚   â”œâ”€â”€ eval/             # MÃ©tricas de avaliaÃ§Ã£o
â”‚   â””â”€â”€ utils/             # Logging e utilitÃ¡rios
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_experiment.py  # Script principal para experimentos via YAML
â”‚   â”œâ”€â”€ run_prerank_ab.py  # Script especializado A/B test
â”‚   â””â”€â”€ evaluate.py        # AvaliaÃ§Ã£o de prediÃ§Ãµes prÃ©-computadas
â”œâ”€â”€ tests/                 # Testes unitÃ¡rios
â”œâ”€â”€ docs/                  # DocumentaÃ§Ã£o tÃ©cnica
â”œâ”€â”€ outputs/               # Resultados e caches
â””â”€â”€ requirements.txt       # DependÃªncias
```

---

## ğŸš€ **Como Usar**

### **Setup do Ambiente**

```bash
# Clone o repositÃ³rio
git clone <repo-url>
cd hybrid-retrieval

# Setup automÃ¡tico
./setup_venv.sh

# Ou manual
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### **ExecuÃ§Ã£o BÃ¡sica**

```bash
# Ativar ambiente
source .venv/bin/activate

# Teste SciFact
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --k 10

# A/B Test completo (MiniLM vs BGE-Large)
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --k 10 \
  --semantic-a "sentence-transformers/all-MiniLM-L6-v2" \
  --semantic-b "BAAI/bge-large-en-v1.5" \
  --graph-model "BAAI/bge-large-en-v1.5" \
  --csv-out ./outputs/scifact_results.csv
```

### **Todos os Datasets**

```bash
python scripts/run_prerank_ab.py \
  --all \
  --k 10 \
  --csv-out ./outputs/all_results.csv
```

---

## âš™ï¸ **ConfiguraÃ§Ãµes AvanÃ§adas**

### **OtimizaÃ§Ãµes para Mac M1 8GB**

```bash
# Reduzir batch size se RAM > 90%
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --ner-batch-size 4 \
  --ner-n-process 1

# Usar GPU (MPS) se disponÃ­vel
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --device mps
```

### **ParÃ¢metros de FAISS**

```bash
# Ãndice otimizado para velocidade
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --faiss-factory "OPQ64,IVF4096,PQ64x8" \
  --faiss-nprobe 64
```

### **Cache e Rebuild**

```bash
# Limpar cache de entidades
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --entity-force-rebuild

# Limpar cache de Ã­ndice
python scripts/run_prerank_ab.py \
  --dataset scifact \
  --index-force-rebuild
```

---

## ğŸ“Š **Resultados Iniciais Obtidos**

### **SciFact Dataset (nDCG@10)**

| Modelo | nDCG@10 | MRR | MAP | Recall | Precision |
|--------|---------|-----|-----|--------|-----------|
| **MiniLM-L6-v2** | **0.552** âœ… | 0.505 | 0.494 | 0.721 | 0.081 |
| **BGE-Large** | 0.414 | 0.370 | 0.355 | 0.584 | 0.065 |

**ObservaÃ§Ã£o**: MiniLM-L6-v2 superou BGE-Large, possivelmente devido a:
- Pesos nÃ£o otimizados para BGE-Large (redundÃ¢ncia semantic + entities)
- Noun chunks gerando ruÃ­do nas entidades

---